\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage[a4paper, margin=1in]{geometry}
\usepackage{amssymb}


\title{Linear Algebra}
\author{Héctor Astudillo}
\date{December 2024}

\begin{document}

\maketitle

\section{Section 1.1 - Vector Spaces}
\subsection*{Vectors}
Let \( F \) be a field. A vector space over \( F \) (denoted by \( EV/F \)) is a set \( V \) (\textbf{whose} elements are vectors that belonging to the vector space), equipped with two operations that satisfy 8 axioms:

\begin{itemize}
    \item \(EV1\) Commutativity of addition: 
    Let \( u, v \in V \), then \( u + v \in V \).
    \item \(EV2\) Associativity of addition:
    For all \( u, v, w \in V \), we have that \( u + (v + w) = (u + v) + w \).
    \item Commutativity of addition: 
    For all \( u, v \in V \), we have that \( u + v = v + u \).
    \item \(EV3\) Elemento neutro aditivo - Additive identity: 
    Exists \( 0 \in V \) such that \( u + 0 = u \) para todo \( u \in V \).
    \item \(EV4\) Elemento inverso aditivo - Additive inverses:
    For each \( u \in V \), exist a unique element \( -u \in V \) such that \( u + (-u) = 0 \).
    \item \(EV5\) Scalar Product/Multiplication: 
    For all \( c, d \in F \) and \( u \in V \), it satisfies that \( (c \cdot d) \cdot u = c \cdot (d \cdot u) \).
    \item \(EV6\) Neutro/Identidad escalar - Identity element of Scalar Multiplication: 
    For all \( u \in V \), it follows that \( 1 \cdot u = u \), where \( 1 \) is the identity element of the product from the field \( F \).
    \item \(EV7\) Distributivity of scalar over field addition: 
    For all \( c, d \in F \) and \( u \in V \), it holds that \( (c + d) \cdot u = c \cdot u + d \cdot u \).
    \item \(EV8\) Distributivity of scalar over vector addition: 
    For all \( c \in F \) y \( u, v \in V \), se cumple \( c \cdot (u + v) = c \cdot u + c \cdot v \).
\end{itemize}

\(F^n\) means n-tuples (adas) of numbers from the field \(F\)

For example, if \(x \in F^n\), then we are talking about a vector with \(n\) entries, whose coefficients belon tot the field \(F\).
\\
\subsection*{Matrices}
Let \(m,n \in N\) y \(F\) a field, we define \(F^{mxn}\) as the set/collection of all \(m x n\) matrices with entries from \(F\)
\\
\\
Remember that:
\\
The sum of matrices is equal entry by entry.
\\
\\
Let us formally define the addition and scalar product on the vectorial space \(F^{mxn}\).
\\

Addition:

Let \(M, N \in F\)...

For every \(i \leq m\) and every \(j \leq m\) we have that \((M + N)_{ij} = M_{ij} + N_{ij}\)
\\

Scalar Product

\(\alpha \in F\), \(m \in F^{mxn}\) such that \(\alpha M \in F^{mxn}\)

Then, \(i \leq m\) and every \(j \leq m\) we have that \((M + N)_{ij} := \alpha \cdot M_{ij}\)
\\
\\
Now we can see that this kind of spaces satisfy the remaining 6 axioms.
\\
\\
Another example... now, we are going to work with functions.

\subsection*{Functions}
Let \(F\) be a field and \(S\) \textbf{a non-empty set}
\\
We define \(F^S\) as \((f | f: S \rightarrow F)\)
\\
In this case, \(S\) is the codomain and \(F\) (the field) is the domain.
\\

Notation:

We can express a function in 2 different ways...
\begin{itemize}
    \item \(f : [a,b] \rightarrow R\)
    \item \(F \in R^{[a,b]}\)
\end{itemize}

Remember the following from Calculus 1:

Let \(f,g \in R^{[a,b]}\) the addition of this functions \(f+g\) maps from \([a,b]\) to \( \mathbb{R}, \forall x \in [a,b]\)

Then, \((f+g)(x) = f(x) + g(x)\)
\\
\\
So it´s the same for our example, now we are going to define the scalar product:

Let \(\alpha \in F\) and \(f \in F^S\)

We want to get \(\alpha \cdot f \in F^S\)

\(\forall t \in S\)

\((\alpha \cdot f)(t) := \alpha \cdot f(t)\)
\\
\\
We already have the addition and scalar product now we can compute the remaining 6 axioms, but there is something else if we want to prove that a functions is equal to another function, we need to prove that the codomain, domain and rule of correspondence it´s the same for both.
\\

Lets shall the \(EV8\)

Let \(\alpha \in F\) and \(f,g \in F^S\)

PD. \(\alpha \cdot (f+g) = \alpha f +\alpha g\)
\\

Domain:

\(dom(\alpha(f+g)) = S\)

\(dom(\alpga f + \alpha g) = S\)
\\

Codomain:

\(cod(\alpha(f+g)) = F\)

\(cod(\alpga f + \alpha g) = F\)
\\

For the rule of correspondence:

Let \(t \in S\)

\((\alpha(f+g))(t) = \alpha \cdot (f+g)(t)\)

\(=\alpha \cdot (f(t) + g(t))\) the field has distributivity

\(= \alpha \cdot f(t) + \alpha \cdot g(t)\)

\(=(\alpha f)(t) + (\alpha g)(t)\)

\(=(\alpha f + \alpha g)(t)\)

\subsection*{Polynomials}

A polynomial with coeficients in \(F\) is:

\[
\sum_{i=0}^{n} a_i x^i = a_0 + a_1 x^1 + a_2x^2 + a_3x^3... +a_nx^n} 
\] 
where \(n \in \mathbb{N} \cup {0}\) and \(\{a_i : 0 \leq i \leq n\} \subsetneq F\)
\\
\\
\(F[x]\) is the collection of all the polynomials with coefficients in \(F\)
\\
\\
Now we need to define the addition and scalar product to shall the remaining 6 axioms. Let´s see how to define formally a polynomial:

Let \(p \in F[x] \rightarrow \exists n \in \mathbf{N}\cup\{0\}\)


\(\qquad \qquad \qquad \quad \exists \{a_i : 0\leq i \leq n\} \subset F\)

Such that 

\[ \(p = \sum_{i=0}^{n} a_ix^i\). \]

The same if we have \(q \in F[x]\)

Let \(q \in F[x] \rightarrow \exists m \in \mathbf{N}\cup\{0\}\)


\(\qquad \qquad \qquad \quad \exists \{b_i : 0\leq i \leq m\} \subset F\)

Such that 

\[ \(q = \sum_{i=0}^{m} b_ix^i\). \]
\\
\textbf{Notice that each polynomial has its own highest degree term and set of coefficients}
\\
The degree term n and m could be any value in Natural field, anyone, so one could be bigger than other, that is the reason why we define \(k\) 

Let \(k := max\{m,n\} \rightarrow \forall n < i \leq k\) \((a_i :=0)\)

\(\qquad \qquad \qquad \qquad \qquad \forall m < i \leq k\) \((b_i :=0)\)

This help us to complete, force the polynomial to have the same degree term (the highest)
\\

Let´s shall and make an abstract definition of addition and scalar product with polynomials and then, prove the remaining 8 axioms.
\\
\\
Addition
\\
We are going to use \(k\) the highest value between m and n that complete the polynomial.

Let \(p, q \in F[X]\)

We define the addition of polynomials as follow:
\[
\(p+ q = \sum_{i=0}^{k} (a_i + b_i) x^i\) \]
\\
\\
Scalar Product

Let \(\alpha \in F\) and \(p \in F[x]\)

Remember how to define formally an polynomial:

\(p \in F(x) \rightarrow \exists n \in \mathbf{N}\cup \{0\}\)

\(\qquad \qquad \quad \exists \{a_i : 0 \leq i \leq m \} \subset F\)
\\
\\
\textbf{Remember this order:}

\textbf{Exist a degree term, the polynomial has a limit, you have to define this.}

\textbf{Then you have to define the coefficient of this polynomial, even define the close interval in the same line, this is the index that can take the coefficients, \(i\)}.
\\
\\
Well I notice that I said "the remaining 6 axioms on each section", which is incorrect, there are 8 axioms cause we define the closure of addition and closure under scalar multiplication. In total are 10 axioms, not 8.
\\
Now let´s shall the \(EV1\) axiom. Commutativity of addition.

Let \(p, q in F[x]\)

P.D. \(p+q = q+ p\)
\\

Now you need to define its coefficients and degree terms of both polynomials, as well as \(k\) the maximal term degree.
\\

Thus, \(p+q = \sum_{i=0}^{k}(a_i+b_i)x^i\)
\\

\(a,b \in F\) and \(F\) is a field with commutativity of addition...

\(\forall \; 0 \leq i \leq k\) ( \(a_i + b_i = b_i + a_i\) )

Then, \(p+q = \sum_{i=0}^{k} (b_i+a_i)x^i = p+q\)
\\
\\
The following outcomes provide us the fundamental properties of a vector space


\subsection*{Theorem 1 - Cancellation law for vector addition}

If \(x, y, z\) are elements of a vector space \(V\) such that \(x+z=y+z \Rightarrow x= y\)
\\

\textbf{This theorem is useful if we want to prove that something is unique, or even to show that 2 variables are equal as we can see in the context of subspaces}
\\
\\
Suppose that \(V\) is a vector space over \(F\) and prove the following...
\begin{itemize}
    \item 1. Exist a \textbf{unique} vector \(w \in V\) such that \(x+w=x\) for each \(x \in V\)

    Additive identity
    \item 2. For each \(x \in V \) exists a unique \(y \in V\) such that \(x+y=0\)

    Additive inverse
\end{itemize}

\textbf{Solution}
\\
1. We need to see that \(w\) is a unique vector...

Let \(w_1, w_2 \in V\) such that \(x+w_1 = x\) and \(x+w_2=x\) for each \(x \in V\)

We apply the theorem 1 in this case... by the cancellation law of addition we obtain that \(w_1 = w_2\)

Thus exists a unique vector \(w \in V \) such that \(x+w=x, \forall x \in V\)

\subsection*{Theorem 1.2 - Three axioms that satisfy vector spaces, focused on vector operations}
\textbf{If \(V\) is a EV/F}, then:

1. \(\forall v \in V (0\cdot v = 0_v)\)

2. \(\forall \alpha \in F\) and \(\forall v \in V ((-\alpha)\cdot v = \alpha (-v) = -(\alpha \cdot v))\) 

3. \( \forall \alpha \in F (\alpha \cdot 0_v = 0_v)\)

\section*{Section 1.3 - Vector Subspaces}

Sub implies that there is another set that contains the subset, for this case.

Let \(V \) a EV/F

We say that \(W \subsetneq V\) is a subspace

If the operations of V, the space, are the same in W since is a subspace then, we need to verify two operations and the remaining axioms. However, it is sufficient to prove only three axioms.

\subsection*{Theorem 1.3 - Three axioms that prove a vector subspace}

Let \(V\) a EV/F and \(W \subset V\)

We will use \(\leq\) to define a subset... \(W\leq V\)

So, \(W \leq v \) if and only if:

1. \(0_v \in W\)

2. \(\forall x,y \in W ( x+ y \in W)\) - Closure of addition over the subspace

3. \(\forall \alpha \in F\) and \(\forall x \in W (\alpha \cdot x \in W)\) - Closure of multiplication over the subspace
\\
\\
To prove an 'if and only if' statement remember that you must demonstrate both the forward implication and the reverse implication, proving just one is not enough...
\\

For example, a way to prove that \(0_v \in W\) you must demonstrate that \(0_v = 0_w\) using the theorem 1, cancellation law of addition.

To prove the remaining 2 axioms, remember operations as functions...

\((+) : W^2 \rightarrow W \subset V\)
\\
\\
\textbf{Don´t forget or confuse the notation of ordered pairs}

\(W\) x \(W = W^2 = \{ (x,y)\;|\; x, y \in W\}\)
\\
\\
For this case:

\(W\) x \(W \rightarrow W \subset V\) - This indicates that the addition of any element from V (which is also in W, as the additive identity) with an element of W \textbf{results in an element of both spaces}.

This help us for the statement 1 and 2.

\((x,y) \rightarrow x+y\)
\\

\(F\) x \(W \rightarrow W\) - This is for the third statement.

\((\alpha,x) \rightarrow \alpha x\)
\\
\\
The next steps are the remaining 8 axioms that define a vector space, but this can be really easy as we show:

We want to prove the commutativity of addition

Let \(x,y \in W\) 

Since \(W \subseteq V,\;\; x,y \in V\) and V is a VS/F...

We conclude that \(x+y=y+x\)

\subsection*{Transposed Matrices}

1. Define the elements...

Let \(m,n \in \mathbb{N}\) and \(M \in F^{\textbf{mxn}} \) 
\\
\\
2. Define the method, in this case is the concept of transpose.

The transpose of \(M\) is the matrix \((M^T) \in F^{\textbf{nxm}}\) 

Notice the degree term that belongs to each matrix

\(\forall \;\textbf{i} \leq m\) and \(\forall \;\textbf{j} \leq n, \;\; ((M^T)_{\textbf{ij}} = M_{\textbf{ji}})\)
\\
\\
\textbf{If \(M^T = M\) we say that M is symmetric}
\\
\\
The collection of symmetrical matrix are a subspace, \textbf{notice that the degree term of this matrices have to be square, for instance, the size n x n}.

Let us see an example of this:

Let \(n \in \mathbb{N}\) and \(M \in F^{\textbf{nxn}} \) 

Define the concept, in this case we want to prove that transposed matrices with size square are a subspace...

\(W := \{M \in F^{\textbf{nxn}} : M^T = M\}\), then \(W \leq F^{\textbf{nxn}}\)
\\

We can prove it with \(0 \in F^{\textbf{nxn}}\)

\(\forall \;\; i,j \leq n\;\; (0_{ij} = 0) \)

Of course 0, the "normal" 0, but this 0 belongs to our subspace \(W\)!
\\

Formally:

1. Define 0 as a matrix and its tranpose

2. Define the limit of the degree term and what you want to prove, in this case:

\((0^t)_{ij} = o_{ji} = 0 \in W\)

Moreover, \(0_{ij} = 0\)

Thus (\(0^t)_{ij} = 0_{ij}\)

Summary: \(0^t = 0\)
\\

Now, prove the closure under addition and multiplication.

Notice we apply the concept of transpose to the operations, we don´t make the operations between the tranposed elements...
\\
\\
Closure under addition

\(\forall M, N \in W \;\;(M+N\in W)\), both are from the same space (still square)

Is \((M+N )^t = M+N\)

Let \(i,j \leq n\)

\((M+N)^t = (M+N)_{ji} 

= M_{ji} + N_{ji}\) by def

I want get the equality...

\(= M_{ij} + N_{ij} = (M+N)_{ij}\)

As \(M,N \in W\),

\(M_{ji} = M^t = M_{ij}\)

\textbf{We are just applying the concept that is over the subspace}

Thus, \(M_{ji} = M_{ij}\)

The same for the matrix \(N\)

Thus, \(M_{ji} + N_{ji} = M_{ij} + N_{ij} = (M+N)_{ij}\)
\\
\\
I didn´t get the following notation but make sense:

\(((M+N)^t)_{ij}\)

"We apply the transpose to the term degree \(ij\), just that... \((M+N)_{ij}\) apply the tranpose, just a comment.
\\
\\
It is the same for the scalar product.
\\
\\
\subsection*{5 subspaces applying functions}
Now we are going to present 5 examples (of different structures/dimensions) of subspaces with a function applied.
\\
\\
1. The following example is to polynomials.

Let \(n \in \mathbb{N}\{0\}\)

We define the collection \(F_n[x] := \{p \in F[x] : \alpha p \leq n\}\)

We want to achieve this statement over each operation.

Obs. In the book... \(\alpha 0 = -1\) but for us \(\alpha 0 = - \infty\)
\\

Notice that we apply a concept (I even don´t know who is but is related with \(\alpha\)), and we are going to prove that \(F_n[x]\) is a subspace.
\\

\begin{itemize}
    \item 0 is the zero from \(F[x]\) moreover, \(\alpha 0 = -\infty < n\)

Thus, \( \in F_n[x]\)

    \item Let \(p, l \in F_n[x]\)

To prove \(p+l \in F_n[x]\)

We can use the following statement without demostrate it: \(\alpha(p+l) \leq max(\alpha p, \alpha l)\)

Since \(p,l \in F[x] \rightarrow \alpha p \leq n,\;\; \alpha l \leq n \)

Then we have \(\alpha p + \alpha l = \alpha (p+l)\) which is less than or equal to n

    \item Let \(\beta \in F\) a scalar, and \(p \in F_n[x]\) 

To prove, \(\beta \cdot p \in F_n[x]\)

We know that \(\beta p \in F[x]\)

\(\alpha(\beta p) = \alpha \beta + \alpha p\)

Notice that if \(\beta = 0\) then, we get \(-\infty\) from \(\alpha \beta\), but if \(\beta\) is not equal to 0 we get a 0

Both cases are in \(F_n[x]\), the subspace
\end{itemize}

2. \(\mathbb{R}^{\mathbb{R}}\) this is a set of functions that maps from \(\mathbb{R}\) to \(\mathbb{R}\), (or is a mapping from x to y)

For this case we define \(C(\mathbb{R})\) as the collection of continuous functions

\(C(\mathbb{R}) := \{f \in \mathbb{R}^{\mathbb{R}} : f \) is continuous\}

\begin{itemize}
    \item Let \(0 : \mathbb{R} \rightarrow \mathbb{R}\)

    Any constant function is contonuous; Thus, \(0 \in \mathbb{R}^{\mathbb{R}}\)

    \item The addition of continuous functions are contonuous

    \item The same for the multiplication
\end{itemize}

\subsection*{Theorem 1.4 - V is a EV/F. If \(W_1 \leq V\) and \(W_2 \leq V\), \(then W_1 \cap W_2 \leq V\)}
This means that the intersection of \mathbf{these} subspaces also satisfy the three axioms that make it a subspace.

Let us demonstrate the theorem with the previous statement:

\begin{itemize}
    \item ¿\(0_v \in W_1 \cap W_2\)?
    
    Since \(W_1 \leq V\) and \(W_2 \leq V\)
    
    Then, \(0_v \in W_1\) and the same for \(W_2\)

    Thus, \(0 \in W_1 \cap W_2\)

    \item Let \(w_1, w_2 \in W_1 \cqp W_2\)

    To prove, the sum of these elements are in the subspace

    Since \(w_1, w_2 \in W_1 \leq W_2 \subset W_1\) and \(W_2\) (both elements in both subspaces of \(V\)).

    Then \(w_1 + w_2 \in W_1\) and \(W_2\)

    Thus, the sum is an element of the intersection.

    \item Let \(\alpha \in F \) and \(w \in W_1\cap W_2\)

    To prove, \(\alpha w \in W_1 \cap W_2\)

    Since \(w \in W_1, W_2\)...

    \(\alpha w \in W_1, W_2\)

    Thus, \(\alpha w \in W_1\cap W_2\)
\end{itemize}

\subsection*{Corollary}

If \(V\) is a EV/V, \(n \in \mathbb{N}\) and \(\forall\; i \leq n...\;(W_i \leq V )\)

\[
\bigcap_{i=1}^n W_i \leq V
\]

Is it true that if \(W_1, W_2 \leq V\), then \(W_1\cup W_2 \leq V\)?

\textbf{No}

\section*{Section 1.4 - Linear Combinations / Generating Set}

Def. \(V\) as a VS/F and \(\emptyset \neq S \leq V\)

Given \(v\in V\), we could say that \(v\) \textbf{is a linear combination if and only if:}

\(\exists n \in \mathbb{N}\) 

\(\exists \{\alpha_i : i\leq n \} \subseteq \textbf{F}\) and

\(\exists \{v_i : i\leq n\} \subseteq \textbf{S}\)

\textbf{Notice that we require the following}:

1. A natural number which serves as the limit of the summation,  from the field \mathbf{N}

2. A coefficient/scalar from the field \textbf{F} 

3. Vectors from a set, this set is the Generating Set...

\[
v = \sum_{i=1}^{n} \alpha_i v_i
\]

This means that some vectors may be expressed as linear combinations, and even a vector space as V could be composed by linear combinations.
\\
\\
Let us see an example of this concept applied on polynomials...

\(p := x^3 - 2x^2 - 5x - 3 \in \mathbb{R}[x]\)

\(q := 3x^3 - 5x^2 - 4x - 9 \in \mathbb{R}[x]\)

We define the set \(S\) with both vectors as its elements, satisfying that \(\emptyset \neq S \subseteq \mathbb{R}[x]\)

We define \(r := 2x^3 - 2x^2 + 12x - 6 \in \mathbb{R}[x]\)
\\
\\
Is the vector \(r\) a linear combination of vectors in \(S\)?

Let´s see that we can only have 2 scalars, the posibilities are:

n= 2 whose elements are \(\{ \alpha_1, \alpha_2\} \subseteq \mathbb{R}\) such that \(r=\alpha_1 p + \alpha_2 q\)
\\

n= 1 such that

\(r = \alpha_1 p\) such that \(\{\alpha_1\} \subseteq \mathbb{R}\)

\(r = \alpha_1 q\) such that \(\{\alpha_1\} \subseteq \mathbb{R}\)

Notice in both cases of n=1, one polynomial is multiplied by 0
\\
\\
These are the cases to get r but, this step is not necesary, at the end the most important part is found the values/scalars to get r, so

What is the value for \(\alpha_1\) and \(\alpha_2\)? Or just the value of \(\alpha_1\) in other case.

To found these values...

We want \(r=\alpha p + \beta q\)

Then, we need to solve the system of equations with the corresponding degree terms factorized. 

At the end we get that \(\alpha = -4\) and \(\beta = 2\)
\\
\\
If a vector is not a linear combination we need to get a contradiction, but are the same steps, solve a system of equations and see for instance that \(0=x\) with \(x\in \mathbb{R}\)\textbackslash \{0\}\

\subsection*{Span(S) - Generated Set}

\(Span(S)\) is by definition the set of all linear combinations of vetors in \(S\).

Observation.

\textbf{Notice that all we need to define a linear combination is the same as what we need for the \(Span\)...}
\\

\(w \in Span(s) \iff\)

1. \(\exists n \in \mathbb{N}\)

2. \(\exists \{ \alpha_i : i \leq n \} \subseteq F\)

3. \(\exists \{ v_i : i \leq n \} \subseteq \textbf{S}\)

\[
w = \sum_{i=1}^{n} \alpha_1 v_1
\]
\\
\\
Let us see an example

\(Span(\{(0,1,0),(1,0,0)\})\)

\(= \{\alpha(0,1,0) + \beta(1,0,0) : \alpha, \beta \in \mathbb{R}\}\)

\(= \{(\beta,\alpha,,0) : \alpha, \beta \in \mathbb{R} \}\)

\textbf{However, this element don´t generate the entire field \mathbf{R}!}

This only generate \textbf{some} elements that belong to \mathbf{R}.

If we try to color the area from a plane in three-dimensional space, we notice that only one side, which serves as its base, is shaded.

\subsection*{Theorem 1.5 - Key Properties \(Span(S)\)}

V is a VS/F and \(S \subseteq V \Rightarrow \)

1. \(Span(S) \leq V\)

2. If \(S\;(generating-subset\:of) \subseteq W (subspace) \leq V (space) \Rightarrow Span(S)\; (generated) \subseteq W \leq V\)
\\
\\
Before proving this theorem, we need notice the following:

\begin{itemize}
    \item If \(S = \emptyset \rightarrow S \subseteq Span(S)\) such that \(Span(0) := \{0_v\}\)
    \item If \(S \neq \emptyset\) \textbf{and \(w \in S \rightarrow n=1, v_1=w, \alpha_1 = 1 \) }, \textbf{\textit{None}} is empty or zero, so we get the linear combination defined as \( \alpha_1 v_1 = 1\cdot w = w \). 
    
    Thus \(w \in Span(S)\).
    
    In addition \(S \subseteq Span(S)\) since \(w\) is the only element that composes the set S
\end{itemize}
\\
\\
Now let´s prove the first statement of the theorem...
\\

\textbf{\textit{Is \(Span(S)\) an subspace of \(V\)?}}

Let´s verify if \(Span(S)\) satisfies the 3 axioms of a subspace:
\\

1. Is \(0_{v-space} \in Span(S)\)?

\begin{quote}
There are two cases where \(S = \emptyset\) and where \(S \neq \emptyset\)
\begin{quote}
\(S = \emptyset\)
\begin{itemize}
    \item With the first case we can prove that \(0_v \in Span(S)\)

In addition we need to demonstrate that in fact, the addition and multiplication is contained on \(Span(S)\)

    \item Let \(x, y \in Span(S) \rightarrow x= \vec{0} =y \rightarrow x+y= \vec{0} \in Span(0)\)

    \item \(\alpha \cdot x = \alpha \cdot \vec{0} = \vec{0} \in Span(S)\)
\end{itemize}

\(S \neq \emptyset\)
\begin{itemize}
    \item \(0_v \in Span(S)\) for \(\exists n \in \mathbb{N},\;\exists \alpha_1 \in F\) and \(z \in Span(S)\) such that \(\alpha_1 \cdot z = 0_v = 0 \cdot z = 0_v \in Span(S)\)

    \item 
\end{itemize}
\end{quote}

\textbf{Remember, with Span(S) we are talking about linear combinations as we define at the early.}

\subsection{Trace of a Matrix}

\end{quote}



\end{document}