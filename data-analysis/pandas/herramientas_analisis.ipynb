{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas para manipulación y análisis de datos\n",
    "\n",
    "Esta construida sobre la base de Numpy, las dos estructuras principales que ofrece pandas son:\n",
    "- Series\n",
    "- Dataframes\n",
    "Si buscas roles como científico de datos, analista, ingeniero de datos o incluso bussiness inteligence uno de los skills que necesitas es el uso de pandas, ademas lo puedes aplicar a un proyecto que añadirás a tu portafolio, puedes usar datasets liberados, estos los podemos encontrar en:\n",
    "- Kaggle\n",
    "- Repositorio de Machine Learning UCI\n",
    "\n",
    "En este caso usaremos el DataSet Online Retail donde identificaremos los productos más vendidos, analizar el comportamiento de clientes y picos de ventas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Información del CSV:\n",
      "        InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0         536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1         536365     71053                  WHITE METAL LANTERN         6   \n",
      "2         536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3         536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4         536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "...          ...       ...                                  ...       ...   \n",
      "541904    581587     22613          PACK OF 20 SPACEBOY NAPKINS        12   \n",
      "541905    581587     22899         CHILDREN'S APRON DOLLY GIRL          6   \n",
      "541906    581587     23254        CHILDRENS CUTLERY DOLLY GIRL          4   \n",
      "541907    581587     23255      CHILDRENS CUTLERY CIRCUS PARADE         4   \n",
      "541908    581587     22138        BAKING SET 9 PIECE RETROSPOT          3   \n",
      "\n",
      "          InvoiceDate  UnitPrice  CustomerID         Country  \n",
      "0        12/1/10 8:26       2.55     17850.0  United Kingdom  \n",
      "1        12/1/10 8:26       3.39     17850.0  United Kingdom  \n",
      "2        12/1/10 8:26       2.75     17850.0  United Kingdom  \n",
      "3        12/1/10 8:26       3.39     17850.0  United Kingdom  \n",
      "4        12/1/10 8:26       3.39     17850.0  United Kingdom  \n",
      "...               ...        ...         ...             ...  \n",
      "541904  12/9/11 12:50       0.85     12680.0          France  \n",
      "541905  12/9/11 12:50       2.10     12680.0          France  \n",
      "541906  12/9/11 12:50       4.15     12680.0          France  \n",
      "541907  12/9/11 12:50       4.15     12680.0          France  \n",
      "541908  12/9/11 12:50       4.95     12680.0          France  \n",
      "\n",
      "[541909 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "path = '/Users/hectorastudillo/py-proyects/data-analysis/pandas/Online_Retail.csv'\n",
    "retail_data = pd.read_csv(path, encoding='latin1') #Se agregó un argumento de más que corrige la codificación del archivo pues por defecto en este caso NO esta en utf-8\n",
    "\n",
    "#retail_data = pd.read_csv(path, encoding='utf-8', errors='ignore')\n",
    "\n",
    "print(type(retail_data))\n",
    "#Estamos trabajando con una clase propia de la libreria\n",
    "print('Información del CSV:\\n',retail_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien nuestra información esta en formato CSV, tambien la podemos presentar en formato de Excel o JSON...\n",
    "- data_excel = pd.read_excel(path)\n",
    "- data_json = pd.read_json(path)\n",
    "\n",
    "# Consejo:\n",
    "Cuando te estes postulando a un puesto de trabajo trata de identificar que tipo de problemas se quiere resolver, entonces cuando estemos desarrollando nuestro portafolio debemos de seleccionar a un set de datos similar a los problemas que se enfrenta la empresa.\n",
    "\n",
    "# DataFrames\n",
    "Veremos como crear dataframes con pandas. \n",
    "Un dataframe en pandas es una estructura de datos bidimensional similar a una tabla en una base de datos o archivo excel, contiene columnas y filas en las que cada columna puede contener un tipo de dato diferente lo que lo hace ideal para el análisis de datos.\n",
    "Los dataframes son el corazón de Pandas.\n",
    "Crearemos un dataframe desde el csv que vamos a utilizar que es el Online_retail.csv...\n",
    "Primero veremos el método HEAD de pandas que me trae un resumen de toda la información que tengo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(retail_data.head())\n",
    "#Esta es una primera manera de crear un dataframe leyendo desde un csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame creado con Numpy (array/matriz) y Pandas(DataFrame/columnas):\n",
      "    A  B  C\n",
      "0  1  2  3\n",
      "1  4  5  6\n",
      "2  7  8  9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Crearemos un array bidimensional\n",
    "data = np.array([[1,2,3], [4,5,6], [7,8,9]])\n",
    "df_from_array = pd.DataFrame(data, columns=['A','B','C']) #Le pasamos de donde obtendrá la infromación, el nombre de las columnas que tendrá nuestro dataframe, esto claramente respecto a la dimensión que tiene nuestra matriz (dimensión 2 array)\n",
    "print('DataFrame creado con Numpy (array/matriz) y Pandas(DataFrame/columnas):\\n',df_from_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Los dataframes tambien pueden ser creados a partir de una lista o diccionario..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame from a list:\n",
      "    ID  Name  Age\n",
      "0   1  Jhon   23\n",
      "1   2   Ana   24\n",
      "Dataframe from a Dictionary:\n",
      "    ID  Name  Age\n",
      "0   1  Jhon   21\n",
      "1   2   Ana   24\n",
      "DataFrame from a Dict(columns) with List(rows):\n",
      "    ID  Name  Age\n",
      "0   1  Jhon   22\n",
      "1   2   Ana   24\n",
      "2   3  Mike   21\n"
     ]
    }
   ],
   "source": [
    "# Tendremos 3 columnas, id, name y age\n",
    "data = [[1, 'Jhon', 23], [2, 'Ana', 24]]\n",
    "df_from_list = pd.DataFrame(data, columns=['ID', 'Name', 'Age'])\n",
    "print('DataFrame from a list:\\n', df_from_list)\n",
    "\n",
    "#Con diccionarios\n",
    "#Igual tengo una lista pero ahora tendremos una clave o llave que directamente le indicaré con su valor, el primero es ID, luego el nombre con su respectivo valor y edad con su respectivo valor...\n",
    "data = [{'ID': 1,\n",
    "         'Name': 'Jhon',\n",
    "         'Age': 21},\n",
    "        {'ID': 2,\n",
    "         'Name': 'Ana',\n",
    "         'Age': 24}]\n",
    "dt_from_dict = pd.DataFrame(data) #Las columnas ya las especificamos dentro del diccionario directamente\n",
    "print('Dataframe from a Dictionary:\\n', dt_from_dict)\n",
    "\n",
    "#Ahora, puede haber el caso en el que las claves son el nombre de cada columna y cada valor que va a ir acompañado de la clave va a ser una lista...\n",
    "\n",
    "data = {'ID': [1,2,3], \n",
    "        'Name': ['Jhon', 'Ana', 'Mike'],\n",
    "        'Age': [22,24,21]}\n",
    "df_from_dict_list = pd.DataFrame(data)\n",
    "print('DataFrame from a Dict(columns) with List(rows):\\n', df_from_dict_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En pandas como bien mencionamos tenemos la herramienta principal que son los dataframes QUE SON DATOS BIDIMENSIONALES, LAS MATRICES SON BIDIMENSIONALES, pero en este caso nos referimos a tablas sin embargo, podemos descomponer dataframes en lo que sería una serie\n",
    "\n",
    "# Series\n",
    "Cada serie corresponde a una columna que equivaldría a un dato uni-dimensional, tendriamos una serie ID, nombre y edad, imagina que son las listas en el último código que hicimos..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame from Series in a Dict:\n",
      "    ID  Name  Age\n",
      "0   1  Jhon   22\n",
      "1   2   Ana   24\n",
      "2   3  Mike   21\n"
     ]
    }
   ],
   "source": [
    "#Partimos desde un diccionario que tendrá como información de filas una serie...\n",
    "data = {'ID': pd.Series([1,2,3]), \n",
    "        'Name': pd.Series(['Jhon', 'Ana', 'Mike']),\n",
    "        'Age': pd.Series([22,24,21])}\n",
    "\n",
    "df_from_series_dict = pd.DataFrame(data)\n",
    "print('DataFrame from Series in a Dict:\\n', df_from_series_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si usas Google Colab, puedes acceder a tus archivos para su lectura sin necesidad de cargarlo manualmente al contenido de Colab con el sigueinte código a partir de Google Drive:\n",
    "\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "path = \"/content/drive/My_drive/online_retail.csv\"\n",
    "\n",
    "data = pd.read_csv(path)\n",
    "print(data.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
