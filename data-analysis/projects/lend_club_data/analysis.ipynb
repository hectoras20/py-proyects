{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My First Project\n",
    "This is the first project in which I will practice the skills I have been learning along my journey to becoming a data scientist.\n",
    "\n",
    "In this case, we are going to analyze data from Lending Club. This platform connects borrowers with investors, and manages all financial trades. It operates as a peer to peer lending system regulated by the plataform itself.\n",
    "\n",
    "The dataset was download from Kaggle - Lending Club Loan Data\n",
    "\n",
    "Let´s load the provided information as a csv with the library Pandas.\n",
    "\n",
    "(In SQL we will query, filter, group and transform data efficiently.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kz/rybrs64563zc2gl94rf00qbw0000gn/T/ipykernel_3408/4253356958.py:6: DtypeWarning: Columns (19,47,55,112,123,124,125,128,129,130,133,139,140,141) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(filepath)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load dataset\n",
    "filepath = '/Users/hectorastudillo/Downloads/archive/Lending_data.csv'\n",
    "\n",
    "data = pd.read_csv(filepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploring\n",
    "Then, we need to understand our data by summarizing how many columns are in the file, identifying the data type of each one, we also want to analyze the information further and think: How can I use all this data?\n",
    "\n",
    "- Obtain simple information of the columns, rows, a especific number of entries:\n",
    "    - .info()\n",
    "    - .head()\n",
    "    - .columns\n",
    "    - num_rows, num_columns = data.shape - This return me 2 variables.\n",
    "\n",
    "- Obtain an specific column and row \n",
    "    - print(data.['Column'][1]) - I can save this into a variable too.\n",
    "\n",
    "- Obtain the type and dataset:\n",
    "    -type(dataset)\n",
    "    - print(dataset)\n",
    "\n",
    "- Obtain statitic information: \n",
    "    - describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2260668 entries, 0 to 2260667\n",
      "Columns: 145 entries, id to settlement_term\n",
      "dtypes: float64(105), int64(4), object(36)\n",
      "memory usage: 2.4+ GB\n",
      "Data obtained with info()\n",
      " None\n",
      "Data obtained with head()\n",
      "    id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
      "0 NaN        NaN       2500         2500           2500.0   36 months   \n",
      "1 NaN        NaN      30000        30000          30000.0   60 months   \n",
      "2 NaN        NaN       5000         5000           5000.0   36 months   \n",
      "3 NaN        NaN       4000         4000           4000.0   36 months   \n",
      "4 NaN        NaN      30000        30000          30000.0   60 months   \n",
      "\n",
      "   int_rate  installment grade sub_grade  ... hardship_payoff_balance_amount  \\\n",
      "0     13.56        84.92     C        C1  ...                            NaN   \n",
      "1     18.94       777.23     D        D2  ...                            NaN   \n",
      "2     17.97       180.69     D        D1  ...                            NaN   \n",
      "3     18.94       146.51     D        D2  ...                            NaN   \n",
      "4     16.14       731.78     C        C4  ...                            NaN   \n",
      "\n",
      "  hardship_last_payment_amount disbursement_method  debt_settlement_flag  \\\n",
      "0                          NaN                Cash                     N   \n",
      "1                          NaN                Cash                     N   \n",
      "2                          NaN                Cash                     N   \n",
      "3                          NaN                Cash                     N   \n",
      "4                          NaN                Cash                     N   \n",
      "\n",
      "  debt_settlement_flag_date settlement_status settlement_date  \\\n",
      "0                       NaN               NaN             NaN   \n",
      "1                       NaN               NaN             NaN   \n",
      "2                       NaN               NaN             NaN   \n",
      "3                       NaN               NaN             NaN   \n",
      "4                       NaN               NaN             NaN   \n",
      "\n",
      "  settlement_amount  settlement_percentage settlement_term  \n",
      "0               NaN                    NaN             NaN  \n",
      "1               NaN                    NaN             NaN  \n",
      "2               NaN                    NaN             NaN  \n",
      "3               NaN                    NaN             NaN  \n",
      "4               NaN                    NaN             NaN  \n",
      "\n",
      "[5 rows x 145 columns]\n",
      "Data obtained with describe()\n",
      "         id  member_id     loan_amnt   funded_amnt  funded_amnt_inv  \\\n",
      "count  0.0        0.0  2.260668e+06  2.260668e+06     2.260668e+06   \n",
      "mean   NaN        NaN  1.504693e+04  1.504166e+04     1.502344e+04   \n",
      "std    NaN        NaN  9.190245e+03  9.188413e+03     9.192332e+03   \n",
      "min    NaN        NaN  5.000000e+02  5.000000e+02     0.000000e+00   \n",
      "25%    NaN        NaN  8.000000e+03  8.000000e+03     8.000000e+03   \n",
      "50%    NaN        NaN  1.290000e+04  1.287500e+04     1.280000e+04   \n",
      "75%    NaN        NaN  2.000000e+04  2.000000e+04     2.000000e+04   \n",
      "max    NaN        NaN  4.000000e+04  4.000000e+04     4.000000e+04   \n",
      "\n",
      "           int_rate   installment    annual_inc  url           dti  ...  \\\n",
      "count  2.260668e+06  2.260668e+06  2.260664e+06  0.0  2.258957e+06  ...   \n",
      "mean   1.309291e+01  4.458076e+02  7.799243e+04  NaN  1.882420e+01  ...   \n",
      "std    4.832114e+00  2.671737e+02  1.126962e+05  NaN  1.418333e+01  ...   \n",
      "min    5.310000e+00  4.930000e+00  0.000000e+00  NaN -1.000000e+00  ...   \n",
      "25%    9.490000e+00  2.516500e+02  4.600000e+04  NaN  1.189000e+01  ...   \n",
      "50%    1.262000e+01  3.779900e+02  6.500000e+04  NaN  1.784000e+01  ...   \n",
      "75%    1.599000e+01  5.933200e+02  9.300000e+04  NaN  2.449000e+01  ...   \n",
      "max    3.099000e+01  1.719830e+03  1.100000e+08  NaN  9.990000e+02  ...   \n",
      "\n",
      "       deferral_term  hardship_amount  hardship_length  hardship_dpd  \\\n",
      "count        10613.0     10613.000000          10613.0  10613.000000   \n",
      "mean             3.0       155.006696              3.0     13.686422   \n",
      "std              0.0       129.113137              0.0      9.728138   \n",
      "min              3.0         0.640000              3.0      0.000000   \n",
      "25%              3.0        59.370000              3.0      5.000000   \n",
      "50%              3.0       119.040000              3.0     15.000000   \n",
      "75%              3.0       213.260000              3.0     22.000000   \n",
      "max              3.0       943.940000              3.0     37.000000   \n",
      "\n",
      "       orig_projected_additional_accrued_interest  \\\n",
      "count                                 8426.000000   \n",
      "mean                                   454.840802   \n",
      "std                                    375.830737   \n",
      "min                                      1.920000   \n",
      "25%                                    174.967500   \n",
      "50%                                    352.605000   \n",
      "75%                                    622.792500   \n",
      "max                                   2680.890000   \n",
      "\n",
      "       hardship_payoff_balance_amount  hardship_last_payment_amount  \\\n",
      "count                    10613.000000                  10613.000000   \n",
      "mean                     11628.036442                    193.606331   \n",
      "std                       7615.161123                    198.694368   \n",
      "min                         55.730000                      0.010000   \n",
      "25%                       5628.730000                     43.780000   \n",
      "50%                      10044.220000                    132.890000   \n",
      "75%                      16114.940000                    284.180000   \n",
      "max                      40306.410000                   1407.860000   \n",
      "\n",
      "       settlement_amount  settlement_percentage  settlement_term  \n",
      "count       33056.000000           33056.000000     33056.000000  \n",
      "mean         5030.606922              47.775600        13.148596  \n",
      "std          3692.027842               7.336379         8.192319  \n",
      "min            44.210000               0.200000         0.000000  \n",
      "25%          2227.000000              45.000000         6.000000  \n",
      "50%          4172.855000              45.000000        14.000000  \n",
      "75%          6870.782500              50.000000        18.000000  \n",
      "max         33601.000000             521.350000       181.000000  \n",
      "\n",
      "[8 rows x 109 columns]\n"
     ]
    }
   ],
   "source": [
    "#Let´s explore the information in the csv.\n",
    "\n",
    "print('Data obtained with info()\\n', data.info()) # To obtain the infomrmation about the csv columns...\n",
    "\n",
    "print('Data obtained with head()\\n', data.head()) # To obtain the information from the first 5 rows.\n",
    "\n",
    "print('Data obtained with describe()\\n', data.describe()) # To obtain basic statistical information only from numercial columns.\n",
    "\n",
    "print('Type of data: ', type(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impressions\n",
    "\n",
    "- There are too many columns, how can we handle them efficiently?\n",
    "\n",
    "- There is not available information in some rows and columns, for example ID and member_id, and that could be a problem.\n",
    "\n",
    "# Data not available and duplicated entries.\n",
    "\n",
    "We need to start making decision for see what do with these data, wheter delete it, complete it. The context-appropriate handling.\n",
    "\n",
    "Now let´s see the data not available by NUMERICAL (int64) columns with isnull() method and duplicated rows with duplicated():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data not avaialbe by columns: \n",
      " id                       2260668\n",
      "member_id                2260668\n",
      "loan_amnt                      0\n",
      "funded_amnt                    0\n",
      "funded_amnt_inv                0\n",
      "                          ...   \n",
      "settlement_status        2227612\n",
      "settlement_date          2227612\n",
      "settlement_amount        2227612\n",
      "settlement_percentage    2227612\n",
      "settlement_term          2227612\n",
      "Length: 145, dtype: int64 \n",
      "\n",
      "Data duplicated by rows: \n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "print('Data not avaialbe by int64 columns: \\n', data.isnull().sum(), '\\n')\n",
    "\n",
    "print('Data duplicated by rows/entries: \\n', data.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unique values over each column\n",
    "Now we can see the unique values from each column making an iteration for each one, we obtain this with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: id\n",
      "Number of unique values: 1\n",
      "Unique values: [nan]\n",
      "--------------------\n",
      "Column: member_id\n",
      "Number of unique values: 1\n",
      "Unique values: [nan]\n",
      "--------------------\n",
      "Column: loan_amnt\n",
      "Number of unique values: 1572\n",
      "Unique values: [ 2500 30000  5000  4000  5550  2000  6000  5500 28000 11200]\n",
      "--------------------\n",
      "Column: funded_amnt\n",
      "Number of unique values: 1572\n",
      "Unique values: [ 2500 30000  5000  4000  5550  2000  6000  5500 28000 11200]\n",
      "--------------------\n",
      "Column: funded_amnt_inv\n",
      "Number of unique values: 10057\n",
      "Unique values: [ 2500. 30000.  5000.  4000.  5550.  2000.  6000.  5500. 28000. 11200.]\n",
      "--------------------\n",
      "Column: term\n",
      "Number of unique values: 2\n",
      "Unique values: [' 36 months' ' 60 months']\n",
      "--------------------\n",
      "Column: int_rate\n",
      "Number of unique values: 673\n",
      "Unique values: [13.56 18.94 17.97 16.14 15.02 14.47 22.35 11.31  8.19 12.98]\n",
      "--------------------\n",
      "Column: installment\n",
      "Number of unique values: 93296\n",
      "Unique values: [ 84.92 777.23 180.69 146.51 731.78 192.45  72.28 203.79 206.44 211.05]\n",
      "--------------------\n",
      "Column: grade\n",
      "Number of unique values: 7\n",
      "Unique values: ['C' 'D' 'B' 'A' 'E' 'F' 'G']\n",
      "--------------------\n",
      "Column: sub_grade\n",
      "Number of unique values: 35\n",
      "Unique values: ['C1' 'D2' 'D1' 'C4' 'C3' 'C2' 'D5' 'B3' 'A4' 'B5']\n",
      "--------------------\n",
      "Column: emp_title\n",
      "Number of unique values: 512695\n",
      "Unique values: ['Chef' 'Postmaster ' 'Administrative' 'IT Supervisor' 'Mechanic'\n",
      " 'Director COE' 'Account Manager' 'Assistant Director'\n",
      " 'Legal Assistant III' nan]\n",
      "--------------------\n",
      "Column: emp_length\n",
      "Number of unique values: 12\n",
      "Unique values: ['10+ years' '6 years' '4 years' '< 1 year' '2 years' '9 years' nan\n",
      " '5 years' '3 years' '7 years']\n",
      "--------------------\n",
      "Column: home_ownership\n",
      "Number of unique values: 6\n",
      "Unique values: ['RENT' 'MORTGAGE' 'OWN' 'ANY' 'NONE' 'OTHER']\n",
      "--------------------\n",
      "Column: annual_inc\n",
      "Number of unique values: 89369\n",
      "Unique values: [ 55000.  90000.  59280.  92000.  57250. 152500.  51000.  65000.  53580.\n",
      " 300000.]\n",
      "--------------------\n",
      "Column: verification_status\n",
      "Number of unique values: 3\n",
      "Unique values: ['Not Verified' 'Source Verified' 'Verified']\n",
      "--------------------\n",
      "Column: issue_d\n",
      "Number of unique values: 139\n",
      "Unique values: ['Dec-2018' 'Nov-2018' 'Oct-2018' 'Sep-2018' 'Aug-2018' 'Jul-2018'\n",
      " 'Jun-2018' 'May-2018' 'Apr-2018' 'Mar-2018']\n",
      "--------------------\n",
      "Column: loan_status\n",
      "Number of unique values: 9\n",
      "Unique values: ['Current' 'Fully Paid' 'Late (31-120 days)' 'In Grace Period'\n",
      " 'Charged Off' 'Late (16-30 days)' 'Default'\n",
      " 'Does not meet the credit policy. Status:Fully Paid'\n",
      " 'Does not meet the credit policy. Status:Charged Off']\n",
      "--------------------\n",
      "Column: pymnt_plan\n",
      "Number of unique values: 2\n",
      "Unique values: ['n' 'y']\n",
      "--------------------\n",
      "Column: url\n",
      "Number of unique values: 1\n",
      "Unique values: [nan]\n",
      "--------------------\n",
      "Column: desc\n",
      "Number of unique values: 124501\n",
      "Unique values: [nan ' '\n",
      " \"I currently have a loan out with CashCall. The interest rate is 96%! At the time I took out the loan, it helped with a family crisis, but now the interest is crazy to be paying. I'd rather be paying my $200 a month to pay down a loan rather than just the interest.   Also, the remainder of my debt has interest rates ranging from 20 - 24%. This includes credit cards, a student loan, and some personal loans. So, I would like to consolidate the rest of my debt and pay a lower interest rate of 15%.  By doing this, I could lower my interest and my monthly payments and save at least $4000 over the next few years.  I do have a bankruptcy that was discharged 3 years ago due to having $40,000 in debt from an uninsured hospital stay. However, I've not missed a payment on anything since.  My credit report does from time time to time relist things as collections and then I have to dispute them as included in bankruptcy and they go back to being listed that way. I'm not sure why the status gets messed up sometimes.   Thank you for your time and consideration! \"\n",
      " 'Consolidate debt'\n",
      " 'This loan will be used solely to consolidate credit card debts accrued while wife was/is unemployed.'\n",
      " 'I have recently purchased and built a new home that I have always dreamed of having.  I would like to complete the project by putting a hottub in my backyard, however; I am not happy with the rate I  have been offered from GE to finance the spa.  I am paying cash for all other improvements, but this is the final phase and finishing touch to my happiness.  I am in the process of consolidating a lot of debt, and went through a minor period of financial woes, but through determination and hard work I have managed to rebound.  My income is fantastic, and I would pay cash for the item, but would like to reserve the money I have saved for future issues if they should arise.  I am a college graduate, responsible, and work for a very good company that is stable in this very unstable market.  I plan to repay this loan in less than 12 months with a 4th quarter bonus I will be receiving.  Thank you for your consideration.'\n",
      " 'Temporary cash flow challenges. Would like this loan to offset mortgage payments-next 90 days. Have owned current residence 22years and have never been late on a payment.  I am self employed in the same business for 31 years in the same location. Wife works for local school district full time.'\n",
      " 'I am looking to pay off my credit card debts.  '\n",
      " 'Hi! So $5,500 doesn\\'t sound like much to be debt free. Well, when you\\'re 24 years old it seems like quite a bit. I was foolish enough to buy into those \"bad credit auto loans\". Here is what happened.. I bought an old car. I had an extremely high monthly payment. I missed other payments on other accounts due to having to pay for repairs in addition to my monthly payment.  The money will pay off the existing loan, and also pay off some credit card debt.  I will be debt free except for my payment to you.  I don\\'t care what the interest rate is, honestly, as long as it doesn\\'t go above 15% (my current car loan rate).   Let me know if you can help me. I would really appreciate it. '\n",
      " 'I developed poor credit in college due to not having a job and not being able to pay my credit card bills all the time. I am a recent graduate and am employeed with a very large and prestigous contractor. I have a steady income and want to get out of debt. Please help me out. Thank you']\n",
      "--------------------\n",
      "Column: purpose\n",
      "Number of unique values: 14\n",
      "Unique values: ['debt_consolidation' 'credit_card' 'house' 'car' 'other' 'vacation'\n",
      " 'home_improvement' 'small_business' 'major_purchase' 'medical']\n",
      "--------------------\n",
      "Column: title\n",
      "Number of unique values: 63155\n",
      "Unique values: ['Debt consolidation' 'Credit card refinancing' 'Home buying'\n",
      " 'Car financing' 'Other' 'Vacation' 'Home improvement' 'Business'\n",
      " 'Major purchase' 'Medical expenses']\n",
      "--------------------\n",
      "Column: zip_code\n",
      "Number of unique values: 957\n",
      "Unique values: ['109xx' '713xx' '490xx' '985xx' '212xx' '461xx' '606xx' '460xx' '327xx'\n",
      " '068xx']\n",
      "--------------------\n",
      "Column: addr_state\n",
      "Number of unique values: 51\n",
      "Unique values: ['NY' 'LA' 'MI' 'WA' 'MD' 'IN' 'IL' 'FL' 'CT' 'GA']\n",
      "--------------------\n",
      "Column: dti\n",
      "Number of unique values: 10846\n",
      "Unique values: [18.24 26.52 10.51 16.74 26.35 37.94  2.4  30.1  21.16 17.43]\n",
      "--------------------\n",
      "Column: delinq_2yrs\n",
      "Number of unique values: 38\n",
      "Unique values: [ 0.  1.  2.  7.  4.  3.  6.  5.  8. 16.]\n",
      "--------------------\n",
      "Column: earliest_cr_line\n",
      "Number of unique values: 755\n",
      "Unique values: ['Apr-2001' 'Jun-1987' 'Apr-2011' 'Feb-2006' 'Dec-2000' 'Sep-2002'\n",
      " 'Nov-2004' 'Nov-1997' 'Aug-1998' 'Apr-2002']\n",
      "--------------------\n",
      "Column: inq_last_6mths\n",
      "Number of unique values: 29\n",
      "Unique values: [ 1.  0.  3.  2.  4.  5. nan  6.  7.  8.]\n",
      "--------------------\n",
      "Column: mths_since_last_delinq\n",
      "Number of unique values: 174\n",
      "Unique values: [nan 71. 32. 17. 22.  6. 43. 38.  8. 30.]\n",
      "--------------------\n",
      "Column: mths_since_last_record\n",
      "Number of unique values: 130\n",
      "Unique values: [ 45.  75.  nan 100. 107.  67. 106.  60.  92.  62.]\n",
      "--------------------\n",
      "Column: open_acc\n",
      "Number of unique values: 92\n",
      "Unique values: [ 9. 13.  8. 10. 12. 18.  1. 19. 38.  6.]\n",
      "--------------------\n",
      "Column: pub_rec\n",
      "Number of unique values: 44\n",
      "Unique values: [ 1.  0.  3.  2.  4.  5.  6.  8.  7. 15.]\n",
      "--------------------\n",
      "Column: revol_bal\n",
      "Number of unique values: 102251\n",
      "Unique values: [ 4341 12315  4599  5468   829 53854     0 38476  8018 65950]\n",
      "--------------------\n",
      "Column: revol_util\n",
      "Number of unique values: 1431\n",
      "Unique values: [10.3 24.2 19.1 78.1  3.6 48.1  nan 69.3 35.2 49.8]\n",
      "--------------------\n",
      "Column: total_acc\n",
      "Number of unique values: 153\n",
      "Unique values: [34. 44. 13. 26.  9. 37. 38. 58. 23. 27.]\n",
      "--------------------\n",
      "Column: initial_list_status\n",
      "Number of unique values: 2\n",
      "Unique values: ['w' 'f']\n",
      "--------------------\n",
      "Column: out_prncp\n",
      "Number of unique values: 364399\n",
      "Unique values: [ 2386.02 29387.75  4787.21  3831.93 29339.02  5302.5   1914.71  5864.01\n",
      "  4786.79  5730.2 ]\n",
      "--------------------\n",
      "Column: out_prncp_inv\n",
      "Number of unique values: 377353\n",
      "Unique values: [ 2386.02 29387.75  4787.21  3831.93 29339.02  5302.5   1914.71  5864.01\n",
      "  4786.79  5730.2 ]\n",
      "--------------------\n",
      "Column: total_pymnt\n",
      "Number of unique values: 1608336\n",
      "Unique values: [ 167.02 1507.11  353.89  286.71 1423.21  377.95  141.56  201.53  405.64\n",
      "  411.86]\n",
      "--------------------\n",
      "Column: total_pymnt_inv\n",
      "Number of unique values: 1299089\n",
      "Unique values: [ 167.02 1507.11  353.89  286.71 1423.21  377.95  141.56  201.53  405.64\n",
      "  411.86]\n",
      "--------------------\n",
      "Column: total_rec_prncp\n",
      "Number of unique values: 487427\n",
      "Unique values: [113.98 612.25 212.79 168.07 660.98 247.5   85.29 135.99 213.21 269.8 ]\n",
      "--------------------\n",
      "Column: total_rec_int\n",
      "Number of unique values: 629835\n",
      "Unique values: [ 53.04 894.86 141.1  118.64 762.23 130.45  56.27  65.54 140.68 135.84]\n",
      "--------------------\n",
      "Column: total_rec_late_fee\n",
      "Number of unique values: 17991\n",
      "Unique values: [ 0.   15.   35.7  22.   52.99 42.32 27.04 23.04 18.81 21.49]\n",
      "--------------------\n",
      "Column: recoveries\n",
      "Number of unique values: 127920\n",
      "Unique values: [   0.   3322.48 1803.35 1702.51 1904.35 2382.66 1383.25 1891.51 1380.57\n",
      " 5239.76]\n",
      "--------------------\n",
      "Column: collection_recovery_fee\n",
      "Number of unique values: 140449\n",
      "Unique values: [  0.     299.0232 162.3015 153.2259 171.3915 214.4394 124.4925 170.2359\n",
      " 124.2513 471.5784]\n",
      "--------------------\n",
      "Column: last_pymnt_d\n",
      "Number of unique values: 136\n",
      "Unique values: ['Feb-2019' 'Jan-2019' nan 'Dec-2018' 'Nov-2018' 'Oct-2018' 'Sep-2018'\n",
      " 'Aug-2018' 'Jul-2018' 'Jun-2018']\n",
      "--------------------\n",
      "Column: last_pymnt_amnt\n",
      "Number of unique values: 692560\n",
      "Unique values: [ 84.92 777.23 180.69 146.51 731.78 192.45  72.28 208.31 206.44 211.05]\n",
      "--------------------\n",
      "Column: next_pymnt_d\n",
      "Number of unique values: 106\n",
      "Unique values: ['Mar-2019' nan 'Feb-2019' 'Apr-2019' 'Dec-2018' 'Sep-2018' 'Aug-2018'\n",
      " 'Feb-2018' 'Jan-2016' 'Sep-2013']\n",
      "--------------------\n",
      "Column: last_credit_pull_d\n",
      "Number of unique values: 141\n",
      "Unique values: ['Feb-2019' 'Jan-2019' 'Dec-2018' nan 'Nov-2018' 'Oct-2018' 'Sep-2018'\n",
      " 'Aug-2018' 'Jul-2018' 'Jun-2018']\n",
      "--------------------\n",
      "Column: collections_12_mths_ex_med\n",
      "Number of unique values: 17\n",
      "Unique values: [ 0.  1.  2.  4.  3.  5.  6.  8.  9. 10.]\n",
      "--------------------\n",
      "Column: mths_since_last_major_derog\n",
      "Number of unique values: 184\n",
      "Unique values: [nan 45. 22.  6. 48. 68. 35. 37. 52. 43.]\n",
      "--------------------\n",
      "Column: policy_code\n",
      "Number of unique values: 1\n",
      "Unique values: [1]\n",
      "--------------------\n",
      "Column: application_type\n",
      "Number of unique values: 2\n",
      "Unique values: ['Individual' 'Joint App']\n",
      "--------------------\n",
      "Column: annual_inc_joint\n",
      "Number of unique values: 17634\n",
      "Unique values: [    nan 104424.  64793.  59500.  55000.  67590. 176000.  85000. 123500.\n",
      " 239000.]\n",
      "--------------------\n",
      "Column: dti_joint\n",
      "Number of unique values: 4019\n",
      "Unique values: [  nan 10.77 18.91 10.59 34.95 24.54 15.42 27.84 14.53 12.77]\n",
      "--------------------\n",
      "Column: verification_status_joint\n",
      "Number of unique values: 4\n",
      "Unique values: [nan 'Verified' 'Not Verified' 'Source Verified']\n",
      "--------------------\n",
      "Column: acc_now_delinq\n",
      "Number of unique values: 10\n",
      "Unique values: [ 0.  1.  2.  3.  4.  6.  5. 14.  7. nan]\n",
      "--------------------\n",
      "Column: tot_coll_amt\n",
      "Number of unique values: 15575\n",
      "Unique values: [   0. 1208.  686. 6389.  160.   66. 2693.  116.  500.  258.]\n",
      "--------------------\n",
      "Column: tot_cur_bal\n",
      "Number of unique values: 487689\n",
      "Unique values: [ 16901. 321915. 110299. 305049. 116007. 685749.    854.  91535.  41882.\n",
      " 349502.]\n",
      "--------------------\n",
      "Column: open_acc_6m\n",
      "Number of unique values: 20\n",
      "Unique values: [ 2.  4.  0.  1.  3.  5.  6.  7. 13.  8.]\n",
      "--------------------\n",
      "Column: open_act_il\n",
      "Number of unique values: 55\n",
      "Unique values: [ 2.  4.  1.  5.  7.  0.  8.  6.  3. 14.]\n",
      "--------------------\n",
      "Column: open_il_12m\n",
      "Number of unique values: 20\n",
      "Unique values: [ 1.  2.  0.  3.  5.  4.  6.  8.  7. 10.]\n",
      "--------------------\n",
      "Column: open_il_24m\n",
      "Number of unique values: 32\n",
      "Unique values: [ 2.  3.  5.  1.  0.  4.  6.  7.  9. 12.]\n",
      "--------------------\n",
      "Column: mths_since_rcnt_il\n",
      "Number of unique values: 406\n",
      "Unique values: [ 2.  3. 14.  5.  4.  7. 23. 62.  1. 36.]\n",
      "--------------------\n",
      "Column: total_bal_il\n",
      "Number of unique values: 162250\n",
      "Unique values: [ 12560.  87153.   7150.  30683.  28845. 131524.      0.  53059.  33864.\n",
      "  39961.]\n",
      "--------------------\n",
      "Column: il_util\n",
      "Number of unique values: 281\n",
      "Unique values: [69. 88. 72. 68. 89. nan 87. 98. 45. 54.]\n",
      "--------------------\n",
      "Column: open_rv_12m\n",
      "Number of unique values: 30\n",
      "Unique values: [ 2.  4.  0.  1.  3.  5.  6.  9.  7. 18.]\n",
      "--------------------\n",
      "Column: open_rv_24m\n",
      "Number of unique values: 51\n",
      "Unique values: [ 7.  5.  2.  0.  4.  1.  6. 12.  3.  8.]\n",
      "--------------------\n",
      "Column: max_bal_bc\n",
      "Number of unique values: 33727\n",
      "Unique values: [ 2137.   998.     0.  3761.   516. 17584.  9413.  3132. 15926.  2837.]\n",
      "--------------------\n",
      "Column: all_util\n",
      "Number of unique values: 189\n",
      "Unique values: [ 28.  57.  35.  70.  54.  58. 100.  74.  73.  48.]\n",
      "--------------------\n",
      "Column: total_rev_hi_lim\n",
      "Number of unique values: 34221\n",
      "Unique values: [ 42000.  50800.  24100.   7000.  23100. 111900.      0.  55500.  22800.\n",
      " 132500.]\n",
      "--------------------\n",
      "Column: inq_fi\n",
      "Number of unique values: 34\n",
      "Unique values: [1. 2. 0. 3. 6. 5. 7. 4. 8. 9.]\n",
      "--------------------\n",
      "Column: total_cu_tl\n",
      "Number of unique values: 63\n",
      "Unique values: [11. 15.  5.  4.  0.  2.  1.  3.  8.  6.]\n",
      "--------------------\n",
      "Column: inq_last_12m\n",
      "Number of unique values: 49\n",
      "Unique values: [ 2.  0.  3.  6.  1.  4.  5. 10.  7.  9.]\n",
      "--------------------\n",
      "Column: acc_open_past_24mths\n",
      "Number of unique values: 58\n",
      "Unique values: [ 9. 10.  4.  5.  8.  3. 12. 15.  2. 11.]\n",
      "--------------------\n",
      "Column: avg_cur_bal\n",
      "Number of unique values: 88598\n",
      "Unique values: [ 1878. 24763. 18383. 30505.  9667. 40338.   854.  5085.  5235.  9197.]\n",
      "--------------------\n",
      "Column: bc_open_to_buy\n",
      "Number of unique values: 91501\n",
      "Unique values: [34360. 13761. 13800.  1239.  8471. 23746.    nan  3034. 13786. 38683.]\n",
      "--------------------\n",
      "Column: bc_util\n",
      "Number of unique values: 1495\n",
      "Unique values: [ 5.9  8.3  0.  75.2  8.9 64.   nan 90.8 35.9 60.6]\n",
      "--------------------\n",
      "Column: chargeoff_within_12_mths\n",
      "Number of unique values: 12\n",
      "Unique values: [ 0.  1.  4.  2.  3.  7.  5.  6.  9. 10.]\n",
      "--------------------\n",
      "Column: delinq_amnt\n",
      "Number of unique values: 2618\n",
      "Unique values: [   0. 2077. 6113.  158. 5445.  200. 8566.  456. 2265.  413.]\n",
      "--------------------\n",
      "Column: mo_sin_old_il_acct\n",
      "Number of unique values: 567\n",
      "Unique values: [140. 163.  87.  62.  53. 195. 169. 145. 166. 139.]\n",
      "--------------------\n",
      "Column: mo_sin_old_rev_tl_op\n",
      "Number of unique values: 788\n",
      "Unique values: [212. 378.  92. 154. 216. 176.  40. 253. 244. 200.]\n",
      "--------------------\n",
      "Column: mo_sin_rcnt_rev_tl_op\n",
      "Number of unique values: 334\n",
      "Unique values: [ 1.  4. 15. 64.  2. 10. 23. 13.  6.  5.]\n",
      "--------------------\n",
      "Column: mo_sin_rcnt_tl\n",
      "Number of unique values: 233\n",
      "Unique values: [ 1.  3. 14.  5.  2.  4.  7. 13.  6. 27.]\n",
      "--------------------\n",
      "Column: mort_acc\n",
      "Number of unique values: 48\n",
      "Unique values: [0. 3. 2. 6. 1. 4. 5. 9. 8. 7.]\n",
      "--------------------\n",
      "Column: mths_since_recent_bc\n",
      "Number of unique values: 547\n",
      "Unique values: [ 1.  4. 77. 64.  2. 20. nan 14.  6.  5.]\n",
      "--------------------\n",
      "Column: mths_since_recent_bc_dlq\n",
      "Number of unique values: 178\n",
      "Unique values: [nan 33. 22. 48. 35. 37. 52. 43. 57. 71.]\n",
      "--------------------\n",
      "Column: mths_since_recent_inq\n",
      "Number of unique values: 27\n",
      "Unique values: [ 2.  4. 14.  5. 13.  3.  1.  6. 15.  7.]\n",
      "--------------------\n",
      "Column: mths_since_recent_revol_delinq\n",
      "Number of unique values: 180\n",
      "Unique values: [ nan  32.  17.  22. 117.   8.  30.  48.  37.  52.]\n",
      "--------------------\n",
      "Column: num_accts_ever_120_pd\n",
      "Number of unique values: 45\n",
      "Unique values: [ 0.  2.  1.  7.  6.  3.  4.  5. 12.  8.]\n",
      "--------------------\n",
      "Column: num_actv_bc_tl\n",
      "Number of unique values: 43\n",
      "Unique values: [ 2.  0.  1.  4.  7. 16.  3.  5.  6.  8.]\n",
      "--------------------\n",
      "Column: num_actv_rev_tl\n",
      "Number of unique values: 58\n",
      "Unique values: [ 5.  4.  3.  2.  6.  0. 12. 20. 19.  9.]\n",
      "--------------------\n",
      "Column: num_bc_sats\n",
      "Number of unique values: 61\n",
      "Unique values: [ 3.  4.  1.  6.  0.  8.  5. 19.  2.  7.]\n",
      "--------------------\n",
      "Column: num_bc_tl\n",
      "Number of unique values: 77\n",
      "Unique values: [ 3.  9.  2.  8. 10. 26.  4.  5.  1.  7.]\n",
      "--------------------\n",
      "Column: num_il_tl\n",
      "Number of unique values: 123\n",
      "Unique values: [16. 27.  4.  7.  9. 23.  5. 15. 20. 13.]\n",
      "--------------------\n",
      "Column: num_op_rev_tl\n",
      "Number of unique values: 82\n",
      "Unique values: [ 7.  8.  6.  2.  9.  0. 14. 33.  3. 10.]\n",
      "--------------------\n",
      "Column: num_rev_accts\n",
      "Number of unique values: 118\n",
      "Unique values: [18. 14.  7.  3. 15. 20. 48.  5.  9. 10.]\n",
      "--------------------\n",
      "Column: num_rev_tl_bal_gt_0\n",
      "Number of unique values: 51\n",
      "Unique values: [ 5.  4.  3.  2.  7.  0. 12. 20. 19.  6.]\n",
      "--------------------\n",
      "Column: num_sats\n",
      "Number of unique values: 92\n",
      "Unique values: [ 9. 13.  8. 10. 12. 18.  1. 19. 38.  6.]\n",
      "--------------------\n",
      "Column: num_tl_120dpd_2m\n",
      "Number of unique values: 8\n",
      "Unique values: [ 0. nan  1.  2.  4.  3.  6.  7.]\n",
      "--------------------\n",
      "Column: num_tl_30dpd\n",
      "Number of unique values: 6\n",
      "Unique values: [ 0.  1.  2.  3.  4. nan]\n",
      "--------------------\n",
      "Column: num_tl_90g_dpd_24m\n",
      "Number of unique values: 35\n",
      "Unique values: [ 0.  1.  2.  4.  5.  6. 16.  9.  3.  7.]\n",
      "--------------------\n",
      "Column: num_tl_op_past_12m\n",
      "Number of unique values: 34\n",
      "Unique values: [3. 6. 0. 5. 4. 2. 1. 7. 9. 8.]\n",
      "--------------------\n",
      "Column: pct_tl_nvr_dlq\n",
      "Number of unique values: 691\n",
      "Unique values: [100.   95.   92.3  78.9  84.6  90.2  76.   80.   86.5  77.8]\n",
      "--------------------\n",
      "Column: percent_bc_gt_75\n",
      "Number of unique values: 285\n",
      "Unique values: [  0.  100.   60.    nan  85.7  26.3  37.5  20.   50.   33.3]\n",
      "--------------------\n",
      "Column: pub_rec_bankruptcies\n",
      "Number of unique values: 13\n",
      "Unique values: [1. 0. 3. 2. 4. 5. 6. 7. 8. 9.]\n",
      "--------------------\n",
      "Column: tax_liens\n",
      "Number of unique values: 43\n",
      "Unique values: [ 0.  1.  2.  4.  6.  3.  5.  8.  7. 15.]\n",
      "--------------------\n",
      "Column: tot_hi_cred_lim\n",
      "Number of unique values: 529973\n",
      "Unique values: [ 60124. 372872. 136927. 385183. 157548. 831687.    854. 117242.  57426.\n",
      " 477390.]\n",
      "--------------------\n",
      "Column: total_bal_ex_mort\n",
      "Number of unique values: 212778\n",
      "Unique values: [ 16901.  99468.  11749.  36151.  29674. 185378.    854.  91535.  41882.\n",
      " 105911.]\n",
      "--------------------\n",
      "Column: total_bc_limit\n",
      "Number of unique values: 20310\n",
      "Unique values: [36500. 15000. 13800.  5000.  9300. 65900.     0. 33100. 21500. 98300.]\n",
      "--------------------\n",
      "Column: total_il_high_credit_limit\n",
      "Number of unique values: 194138\n",
      "Unique values: [ 18124.  94072.  10000.  44984.  32332. 203159.      0.  61742.  34626.\n",
      "  89600.]\n",
      "--------------------\n",
      "Column: revol_bal_joint\n",
      "Number of unique values: 56876\n",
      "Unique values: [   nan 10286. 24654.  6902. 29704. 32918. 19599. 34437.  7980. 64367.]\n",
      "--------------------\n",
      "Column: sec_app_earliest_cr_line\n",
      "Number of unique values: 664\n",
      "Unique values: [nan 'May-2002' 'Aug-2003' 'May-2003' 'Oct-1999' 'Dec-1996' 'May-2007'\n",
      " 'Oct-2006' 'Nov-1996' 'Jul-1997']\n",
      "--------------------\n",
      "Column: sec_app_inq_last_6mths\n",
      "Number of unique values: 8\n",
      "Unique values: [nan  2.  0.  1.  4.  3.  5.  6.]\n",
      "--------------------\n",
      "Column: sec_app_mort_acc\n",
      "Number of unique values: 24\n",
      "Unique values: [nan  3.  2.  0.  1.  4.  6.  7.  5. 10.]\n",
      "--------------------\n",
      "Column: sec_app_open_acc\n",
      "Number of unique values: 68\n",
      "Unique values: [nan  2.  9.  6. 16. 17.  3. 10. 14. 24.]\n",
      "--------------------\n",
      "Column: sec_app_revol_util\n",
      "Number of unique values: 1217\n",
      "Unique values: [ nan 44.1 78.9 47.9 48.8 92.  95.7 71.8 26.3 60.9]\n",
      "--------------------\n",
      "Column: sec_app_open_act_il\n",
      "Number of unique values: 41\n",
      "Unique values: [nan  0.  1.  6.  3.  2.  5.  7. 16.  8.]\n",
      "--------------------\n",
      "Column: sec_app_num_rev_accts\n",
      "Number of unique values: 87\n",
      "Unique values: [nan  6. 12. 21. 15. 11.  5.  9. 10. 19.]\n",
      "--------------------\n",
      "Column: sec_app_chargeoff_within_12_mths\n",
      "Number of unique values: 23\n",
      "Unique values: [nan  0. 10.  1.  2.  3.  8.  4.  5.  6.]\n",
      "--------------------\n",
      "Column: sec_app_collections_12_mths_ex_med\n",
      "Number of unique values: 19\n",
      "Unique values: [nan  0.  2. 10.  1.  3.  4.  5.  8.  6.]\n",
      "--------------------\n",
      "Column: sec_app_mths_since_last_major_derog\n",
      "Number of unique values: 141\n",
      "Unique values: [nan 46. 25. 37. 70. 64. 80. 20. 49. 35.]\n",
      "--------------------\n",
      "Column: hardship_flag\n",
      "Number of unique values: 2\n",
      "Unique values: ['N' 'Y']\n",
      "--------------------\n",
      "Column: hardship_type\n",
      "Number of unique values: 2\n",
      "Unique values: [nan 'INTEREST ONLY-3 MONTHS DEFERRAL']\n",
      "--------------------\n",
      "Column: hardship_reason\n",
      "Number of unique values: 10\n",
      "Unique values: [nan 'UNEMPLOYMENT' 'NATURAL_DISASTER' 'EXCESSIVE_OBLIGATIONS' 'MEDICAL'\n",
      " 'INCOME_CURTAILMENT' 'DISABILITY' 'REDUCED_HOURS' 'FAMILY_DEATH'\n",
      " 'DIVORCE']\n",
      "--------------------\n",
      "Column: hardship_status\n",
      "Number of unique values: 4\n",
      "Unique values: [nan 'ACTIVE' 'COMPLETED' 'BROKEN']\n",
      "--------------------\n",
      "Column: deferral_term\n",
      "Number of unique values: 2\n",
      "Unique values: [nan  3.]\n",
      "--------------------\n",
      "Column: hardship_amount\n",
      "Number of unique values: 8951\n",
      "Unique values: [   nan 378.39 203.67 378.9  126.27 119.59 243.56 159.94 241.9  134.81]\n",
      "--------------------\n",
      "Column: hardship_start_date\n",
      "Number of unique values: 27\n",
      "Unique values: [nan 'Feb-2019' 'Oct-2018' 'Nov-2018' 'Sep-2018' 'Jan-2019' 'Dec-2018'\n",
      " 'Aug-2018' 'Jul-2018' 'May-2018']\n",
      "--------------------\n",
      "Column: hardship_end_date\n",
      "Number of unique values: 28\n",
      "Unique values: [nan 'Apr-2019' 'Dec-2018' 'Jan-2019' 'Feb-2019' 'Oct-2018' 'May-2019'\n",
      " 'Mar-2019' 'Nov-2018' 'Aug-2018']\n",
      "--------------------\n",
      "Column: payment_plan_start_date\n",
      "Number of unique values: 27\n",
      "Unique values: [nan 'Feb-2019' 'Oct-2018' 'Nov-2018' 'Dec-2018' 'Jan-2019' 'Sep-2018'\n",
      " 'Mar-2019' 'Aug-2018' 'Jun-2018']\n",
      "--------------------\n",
      "Column: hardship_length\n",
      "Number of unique values: 2\n",
      "Unique values: [nan  3.]\n",
      "--------------------\n",
      "Column: hardship_dpd\n",
      "Number of unique values: 35\n",
      "Unique values: [nan 22.  0. 18. 23. 28. 29.  7. 16. 11.]\n",
      "--------------------\n",
      "Column: hardship_loan_status\n",
      "Number of unique values: 6\n",
      "Unique values: [nan 'Late (16-30 days)' 'Issued' 'Current' 'Late (31-120 days)'\n",
      " 'In Grace Period']\n",
      "--------------------\n",
      "Column: orig_projected_additional_accrued_interest\n",
      "Number of unique values: 7314\n",
      "Unique values: [    nan 1135.17  611.01 1136.7   378.81  358.77  730.68  479.82  725.7\n",
      "  404.43]\n",
      "--------------------\n",
      "Column: hardship_payoff_balance_amount\n",
      "Number of unique values: 10592\n",
      "Unique values: [     nan 15351.85 40149.35 23090.22  8096.8   9649.7  12701.26 19071.77\n",
      " 19495.24  9674.48]\n",
      "--------------------\n",
      "Column: hardship_last_payment_amount\n",
      "Number of unique values: 8796\n",
      "Unique values: [        nan 1.04541e+03 1.01000e+00 1.21000e+00 2.92830e+02 3.46430e+02\n",
      " 1.00000e-01 1.90000e-01 4.70130e+02 2.00000e-01]\n",
      "--------------------\n",
      "Column: disbursement_method\n",
      "Number of unique values: 2\n",
      "Unique values: ['Cash' 'DirectPay']\n",
      "--------------------\n",
      "Column: debt_settlement_flag\n",
      "Number of unique values: 2\n",
      "Unique values: ['N' 'Y']\n",
      "--------------------\n",
      "Column: debt_settlement_flag_date\n",
      "Number of unique values: 83\n",
      "Unique values: [nan 'Feb-2019' 'Dec-2018' 'Jan-2019' 'Nov-2018' 'Oct-2018' 'Sep-2018'\n",
      " 'Aug-2018' 'Jul-2018' 'Jun-2018']\n",
      "--------------------\n",
      "Column: settlement_status\n",
      "Number of unique values: 4\n",
      "Unique values: [nan 'ACTIVE' 'COMPLETE' 'BROKEN']\n",
      "--------------------\n",
      "Column: settlement_date\n",
      "Number of unique values: 90\n",
      "Unique values: [nan 'Feb-2019' 'Dec-2018' 'Jan-2019' 'Nov-2018' 'Oct-2018' 'Sep-2018'\n",
      " 'Aug-2018' 'Jul-2018' 'Jun-2018']\n",
      "--------------------\n",
      "Column: settlement_amount\n",
      "Number of unique values: 21520\n",
      "Unique values: [   nan  5443. 10119. 23506.  3422. 13175.  5180.  1059. 14333.  5694.]\n",
      "--------------------\n",
      "Column: settlement_percentage\n",
      "Number of unique values: 2046\n",
      "Unique values: [  nan 65.   65.01 60.   64.97 60.01 64.99 50.   45.   47.16]\n",
      "--------------------\n",
      "Column: settlement_term\n",
      "Number of unique values: 41\n",
      "Unique values: [nan 18.  6. 14. 12. 24.  1. 16. 17.  3.]\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "unique_values = {\n",
    "    col : data[col].unique() for col in data.columns\n",
    "}\n",
    "\"\"\"\n",
    "We create a dictionary such that its keys are all the columns called col, then we iterate over each column to obtain its unique values\n",
    "\"For each column into the columns from the dataset, obtain its unique value\"\n",
    "\n",
    "In PANDAS, the notation to specify a column is with [], dataset[column]\n",
    "\"\"\"\n",
    "\n",
    "# Now let´s start visualizing these values\n",
    "\n",
    "for col, values in unique_values.items():\n",
    "    print(f'Column: {col}')\n",
    "    print(f'Number of unique values: {len(values)}')\n",
    "    print(f'Unique values: {values[:10]}') # We obtain the first 10 values\n",
    "    print('-'*20) # Separation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data cleansing\n",
    "We need to perform data cleaning before stating the analysis. WE NEED TO CREATE A NEW DATAFRAME FOR THAT.\n",
    "\n",
    "This we will make it with the following methods:\n",
    "- drop.duplicates()\n",
    "- dropna() using the parameter \"subset\" to specify a column or columns, remember the notation ['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data before the handling:\n",
      " id                       0\n",
      "member_id                0\n",
      "loan_amnt                0\n",
      "funded_amnt              0\n",
      "funded_amnt_inv          0\n",
      "                        ..\n",
      "settlement_status        0\n",
      "settlement_date          0\n",
      "settlement_amount        0\n",
      "settlement_percentage    0\n",
      "settlement_term          0\n",
      "Length: 145, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_cleaned = data.dropna()\n",
    "\n",
    "# Now, I want to check if all the columns are cleaned.\n",
    "print('Data before the handling:\\n', data_cleaned.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis \n",
    "Check if you need to creat another dataframe (as we created for data cleansing) or just specify the colums to use.\n",
    "# Create DataFrames from a csv (or Series - Unidimensional, similar to a column)\n",
    "\n",
    "Example, **we will create a bidimensional length dataframe with numpy and pandas**\n",
    "    data = np.array([[1,2,3], [4,5,6], [7,8,9]])\n",
    "    df_from_array = pd.DataFrame(data, columns=['A','B','C']) These are the name of columns.\n",
    "\n",
    "There is another example creating from dictionaries.\n",
    "\n",
    "# What you want to solve?\n",
    "What can we obtain from this dataset that could help in the development of the club?\n",
    "\n",
    "- We can compute the expected value for some columns, we need to check each one and see if it is useful for us.\n",
    "- Date more common where customers apply for a debt.\n",
    "\n",
    "A customer could obtain a credit from the club? Can apply?\n",
    "- I can make a filter for some columns that indicates if the customer has checks-offs, deliquencies, ratios specifics that contain the dataset.\n",
    "- Co-borrowers could mean less risk\n",
    "\n",
    "# We will use specific columns, do not need to use the 150 columns at the same time.\n",
    "Annual incomes provided by customers\n",
    "- We can plot the income amounts of customers.\n",
    "- Use statistic tools like quartiles for that specific column.\n",
    "\n",
    "# Analyze an specific column and row:\n",
    "- print(data.['Column'][1]) - I can save this into a variable too.\n",
    "- column_analyzed = data.['Column'].mean() - This previous method may change to our preference.\n",
    "- .count() uses the same syntaxis. **Always be careful with null values for every calculation**\n",
    "\n",
    "# Use \"none\" value for empty data\n",
    "If there are none values into the empty data from the columns, in the sum this does not have value it is 0, and for counting this are omitted.\n",
    "\n",
    "# Analyze again the columns \n",
    "What new columns can we create, add, operate on, or even transform their data type?\n",
    "\n",
    "For example:\n",
    "- Make operation with each other: \n",
    "    - data_cleaned['NewColumn'] = data_cleaned['Column1'] * data_cleaned['Column2']\n",
    "\n",
    "- Change the data type of one column: \n",
    "    - data_cleaned['ColumnHandle'] = pd.to_datetime(data_cleaned['ColumnHandle'])\n",
    "    We can check the changes with the method info().\n",
    "\n",
    "-Divide the information from a column with a data type specific, usually with datetime data:\n",
    "    - data_cleaned['SubColumns'] = data_cleaned['DatatimeColumn'].dt.year, for example\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
