{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a conglomerar todos los conceptos vistos en las 3 librerias, la idea es que usemos Online Retail, nuestro dataset seleccionado (revisa directorio de Pandas/herramientas) pero podemos hacerlo con el dataset de nuestra preferencia.\n",
    "- Considera el objetivo y el contexto de los datos que estas manejando.\n",
    "Tienes que hacerte varias preguntas, entre ellas:\n",
    "- ¿Qué es lo que buscan los stackeholeds?\n",
    "- ¿Que pretendes hallar?\n",
    "- ¿Cuál es la información importante que podemos resaltar de los datos?\n",
    "\n",
    "# Exploración de datos\n",
    "Cargaremos los datos, podemos hacer una visualización normal de los datos, nombre de columnas, número de filas, incluso esto lo podemos hacer con el método info(), en este punto ya debes de tener tus pregutas e identificar de donde vas a sacar la información que nos va ayudar en este contexto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Cargar dataset\n",
    "filepath = '/Users/hectorastudillo/py-proyects/data-analysis/proyects/Online_Retail.csv'\n",
    "data = pd.read_csv(filepath, encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que sigue es explorar nuestros datos...\n",
    "\n",
    "Podemos usar los siguientes métodos \n",
    "- info()\n",
    "- head()\n",
    "- describe(), información de estadística básica de las columnas de tipo númericas, veremos cuartiles, desviación estandar, promedio, mediana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 541909 entries, 0 to 541908\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   InvoiceNo    541909 non-null  object \n",
      " 1   StockCode    541909 non-null  object \n",
      " 2   Description  540455 non-null  object \n",
      " 3   Quantity     541909 non-null  int64  \n",
      " 4   InvoiceDate  541909 non-null  object \n",
      " 5   UnitPrice    541909 non-null  float64\n",
      " 6   CustomerID   406829 non-null  float64\n",
      " 7   Country      541909 non-null  object \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 33.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos ver cuantos datos nos faltan o FILAS DUPLICADAS INCLUSIVE en el set de datos. NO ES NECESARIO QUE USE EL PRINT EN AMBOS, ya viene digamos por defecto que se mostrarán con estos métodos, acceeder a esta información.\n",
    "\n",
    "Con ello deberiamos de empezar a tomar decisiones para ver que hacer con esos datos, si eliminarlos, rellenarlos, el tratamiento que convenga segun el contexto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos NO disponibles por columna:\n",
      " InvoiceNo           0\n",
      "StockCode           0\n",
      "Description      1454\n",
      "Quantity            0\n",
      "InvoiceDate         0\n",
      "UnitPrice           0\n",
      "CustomerID     135080\n",
      "Country             0\n",
      "dtype: int64\n",
      "Filas duplicadas:\n",
      " 5268\n"
     ]
    }
   ],
   "source": [
    "#Quiero la suma total de los datos faltantes\n",
    "print('Datos NO disponibles por columna:\\n', data.isnull().sum())\n",
    "\n",
    "#Cuantos son los duplicados\n",
    "print('Filas duplicadas:\\n', data.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora obtendremos los valores únicos, esto lo haremos ITERANDO en cada una de las columnas.\n",
    "Por ejemplo en la columna de Country podré obtener cuantos paises podemos observar en este set de datos. \n",
    "\n",
    "Lo haremos de forma general pero yo debería de preguntarme de que columnas quiero los datos únicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columna: InvoiceNo\n",
      "Número de valores únicos: 25900\n",
      "Valores únicos: ['536365' '536366' '536367' '536368' '536369' '536370' '536371' '536372'\n",
      " '536373' '536374']\n",
      "--------------------\n",
      "Columna: StockCode\n",
      "Número de valores únicos: 4070\n",
      "Valores únicos: ['85123A' '71053' '84406B' '84029G' '84029E' '22752' '21730' '22633'\n",
      " '22632' '84879']\n",
      "--------------------\n",
      "Columna: Description\n",
      "Número de valores únicos: 4224\n",
      "Valores únicos: ['WHITE HANGING HEART T-LIGHT HOLDER' 'WHITE METAL LANTERN'\n",
      " 'CREAM CUPID HEARTS COAT HANGER' 'KNITTED UNION FLAG HOT WATER BOTTLE'\n",
      " 'RED WOOLLY HOTTIE WHITE HEART.' 'SET 7 BABUSHKA NESTING BOXES'\n",
      " 'GLASS STAR FROSTED T-LIGHT HOLDER' 'HAND WARMER UNION JACK'\n",
      " 'HAND WARMER RED POLKA DOT' 'ASSORTED COLOUR BIRD ORNAMENT']\n",
      "--------------------\n",
      "Columna: Quantity\n",
      "Número de valores únicos: 722\n",
      "Valores únicos: [ 6  8  2 32  3  4 24 12 48 18]\n",
      "--------------------\n",
      "Columna: InvoiceDate\n",
      "Número de valores únicos: 23260\n",
      "Valores únicos: ['12/1/10 8:26' '12/1/10 8:28' '12/1/10 8:34' '12/1/10 8:35'\n",
      " '12/1/10 8:45' '12/1/10 9:00' '12/1/10 9:01' '12/1/10 9:02'\n",
      " '12/1/10 9:09' '12/1/10 9:32']\n",
      "--------------------\n",
      "Columna: UnitPrice\n",
      "Número de valores únicos: 1630\n",
      "Valores únicos: [2.55 3.39 2.75 7.65 4.25 1.85 1.69 2.1  3.75 1.65]\n",
      "--------------------\n",
      "Columna: CustomerID\n",
      "Número de valores únicos: 4373\n",
      "Valores únicos: [17850. 13047. 12583. 13748. 15100. 15291. 14688. 17809. 15311. 14527.]\n",
      "--------------------\n",
      "Columna: Country\n",
      "Número de valores únicos: 38\n",
      "Valores únicos: ['United Kingdom' 'France' 'Australia' 'Netherlands' 'Germany' 'Norway'\n",
      " 'EIRE' 'Switzerland' 'Spain' 'Poland']\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "unique_values = {\n",
    "    col : data[col].unique() for col in data.columns} \n",
    "#Vamos a crear un diccionario con comprehension\n",
    "\n",
    "#Empezamos a visualizar estos valores\n",
    "for col, values in unique_values.items():\n",
    "    print(f'Columna: {col}')\n",
    "    print(f'Número de valores únicos: {len(values)}')\n",
    "    print(f'Valores únicos: {values[:10]}') #Imprimimos los primeros 10\n",
    "    print('-'*20) # Separación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza\n",
    "La etapa 3 corresponde a la limpieza de datos.\n",
    "- Eliminar filas duplicadas, para ello vamos a crear un NUEVO dataframe, no vamos a modificar directamente en el que exploramos, puede ser útil de guía."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos NO disponibles por columna:\n",
      " InvoiceNo      0\n",
      "StockCode      0\n",
      "Description    0\n",
      "Quantity       0\n",
      "InvoiceDate    0\n",
      "UnitPrice      0\n",
      "CustomerID     0\n",
      "Country        0\n",
      "dtype: int64\n",
      "Filas duplicadas:\n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "data_cleaned = data.drop_duplicates()\n",
    "data_cleaned = data_cleaned.dropna(subset=['CustomerID']) \n",
    "#ELIMINAR VALORES FALTANTES\n",
    "# Especificio la columna que se aplicará este método\n",
    "\n",
    "#Quiero la suma total de los datos faltantes\n",
    "print('Datos NO disponibles por columna:\\n', data_cleaned.isnull().sum())\n",
    "\n",
    "#Cuantos son los duplicados\n",
    "print('Filas duplicadas:\\n', data_cleaned.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de la limpieza sigue estar 100% en el rol de científico de datos, peinsa segun las columnas que tenemos en el set de datos actualemnte cuales son las nuevas que podemos obtener, transoformar quiza un tipo de dato.\n",
    "\n",
    "# Completar columnas \n",
    "Por ejemplo, podemos crear la columna que mutiplica la columna cantidad con la de precio unitario...\n",
    "\n",
    "Podemos convertir de nuevo el tipo de dato de InvoirceDate de objet a date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kz/rybrs64563zc2gl94rf00qbw0000gn/T/ipykernel_13964/1299663578.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data_cleaned['InvoiceDate'] = pd.to_datetime(data_cleaned['InvoiceDate']) #Podemos comprobar con el método info()\n"
     ]
    }
   ],
   "source": [
    "data_cleaned['TotalAmount'] = data_cleaned['Quantity'] * data_cleaned['UnitPrice']\n",
    "\n",
    "data_cleaned['InvoiceDate'] = pd.to_datetime(data_cleaned['InvoiceDate']) #Podemos comprobar con el método info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como esta columna de InvoiceDate ya está en una serie de tiempo puedo desglozarla y crear nuevas columnas, recuerda las buenas prácticas de SQL, normalización, datos atómicos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned['Year'] = data_cleaned['InvoiceDate'].dt.year\n",
    "\n",
    "data_cleaned['Month'] = data_cleaned['InvoiceDate'].dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hallar insights o información que nos puede proprocionar\n",
    "Aquí es donde realizamos sumas totales u operadores tanto estadísticos o cualquier otra herrmaienta operacional.\n",
    "Analizar las ventas por año, semestre, trimestre, etc.\n",
    "\n",
    "Recordatorio de manipulación de código:\n",
    "- Indica la columna en la que se establecerán o CREARÁ la información, en este caso agrupará con base a ellas \n",
    "- Indica la columna con la que TRABAJRÁ, osea que va a manipular\n",
    "- Operación a aplicar a la columna con la que se trabaja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year amounts:\n",
      " Year\n",
      "2010     552372.860\n",
      "2011    7726146.564\n",
      "Name: TotalAmount, dtype: float64\n",
      "Información por semestre:\n",
      " Year  Semester\n",
      "2010  2            552372.860\n",
      "2011  1           3166939.041\n",
      "      2           4559207.523\n",
      "Name: TotalAmount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# YA TENEMOS EN ESTE PUNTO CREADA LA COLUMNA YEAR DE DONDE TOMARÁ VALORES UÚNICOS EL NUEVO DATASET \n",
    "#TRABAJAREMOS con el conjunto de datos de TotalAmount creado\n",
    "\n",
    "sales_by_year = data_cleaned.groupby('Year')['TotalAmount'].sum()\n",
    "# Agruparmos por años\n",
    "# Donde queremos almacenar o guardar esa información\n",
    "print('Year amounts:\\n', sales_by_year)\n",
    "\n",
    "# SEMESTRAL\n",
    "#Creamos nuestra columna que utilizaremos para tomar valores únicos, como no la tenemos creada aún, usaremos/APLICAREMOS una lambda function...\n",
    "\n",
    "data_cleaned['Semester'] = data_cleaned['Month'].apply(lambda x : 1 if x <= 6 else 2)\n",
    "# 1 para el primer semestre\n",
    "# 2 para el segundo semestre\n",
    "\n",
    "#Creamos DataFrame, en este caso como solo tenemos 2 años podemos establecer que agrupe por valores únicos de año y semestre\n",
    "# TRABAJARÁ con TotalAmount y aplicamos la operación\n",
    "sales_by_semester = data_cleaned.groupby(['Year', 'Semester'])['TotalAmount'].sum()\n",
    "print('Información por semestre:\\n', sales_by_semester)\n",
    "\n",
    "#Creamos nuevos dataframes a partir de la información que ya teníamos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
