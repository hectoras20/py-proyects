{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas para manipulación y análisis de datos\n",
    "\n",
    "Esta construida sobre la base de Numpy, las dos estructuras principales que ofrece pandas son:\n",
    "- Series\n",
    "- Dataframes\n",
    "\n",
    "Si buscas roles como científico de datos, analista, ingeniero de datos o incluso bussiness inteligence uno de los skills que necesitas es el uso de pandas, ademas lo puedes aplicar a un proyecto para tu portafolio, puedes usar datasets liberados, estos los podemos encontrar en:\n",
    "- Kaggle\n",
    "- Repositorio de Machine Learning UCI\n",
    "\n",
    "En este caso usaremos el DataSet Online Retail donde identificaremos los productos más vendidos, analizar el comportamiento de customers y picos de ventas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hectorastudillo/py-proyects/data-analysis/env_analysis/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Información del CSV:\n",
      "        InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0         536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1         536365     71053                  WHITE METAL LANTERN         6   \n",
      "2         536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3         536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4         536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "...          ...       ...                                  ...       ...   \n",
      "541904    581587     22613          PACK OF 20 SPACEBOY NAPKINS        12   \n",
      "541905    581587     22899         CHILDREN'S APRON DOLLY GIRL          6   \n",
      "541906    581587     23254        CHILDRENS CUTLERY DOLLY GIRL          4   \n",
      "541907    581587     23255      CHILDRENS CUTLERY CIRCUS PARADE         4   \n",
      "541908    581587     22138        BAKING SET 9 PIECE RETROSPOT          3   \n",
      "\n",
      "          InvoiceDate  UnitPrice  customerserID         Country  \n",
      "0        12/1/10 8:26       2.55     17850.0  United Kingdom  \n",
      "1        12/1/10 8:26       3.39     17850.0  United Kingdom  \n",
      "2        12/1/10 8:26       2.75     17850.0  United Kingdom  \n",
      "3        12/1/10 8:26       3.39     17850.0  United Kingdom  \n",
      "4        12/1/10 8:26       3.39     17850.0  United Kingdom  \n",
      "...               ...        ...         ...             ...  \n",
      "541904  12/9/11 12:50       0.85     12680.0          France  \n",
      "541905  12/9/11 12:50       2.10     12680.0          France  \n",
      "541906  12/9/11 12:50       4.15     12680.0          France  \n",
      "541907  12/9/11 12:50       4.15     12680.0          France  \n",
      "541908  12/9/11 12:50       4.95     12680.0          France  \n",
      "\n",
      "[541909 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "path = '/Users/hectorastudillo/py-proyects/data-analysis/pandas/Online_Retail.csv'\n",
    "retail_data = pd.read_csv(path, encoding='latin1') #Se agregó un argumento de más que corrige la codificación del archivo pues por defecto en este caso NO esta en utf-8\n",
    "\n",
    "#retail_data = pd.read_csv(path, encoding='utf-8', errors='ignore')\n",
    "\n",
    "print(type(retail_data))\n",
    "#Estamos trabajando con una clase propia de la libreria\n",
    "print('Información del CSV:\\n',retail_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien nuestra información esta en formato CSV, tambien la podemos presentar en formato de Excel o JSON...\n",
    "- data_excel = pd.read_excel(path)\n",
    "- data_json = pd.read_json(path)\n",
    "\n",
    "# Consejo:\n",
    "Cuando te estes postulando a un puesto de trabajo trata de identificar que tipo de problemas se quiere resolver, entonces cuando estemos desarrollando nuestro portafolio debemos de seleccionar a un set de datos similar a los problemas que se enfrenta la empresa.\n",
    "\n",
    "# DataFrames\n",
    "Veremos como crear dataframes con pandas. \n",
    "Un dataframe en pandas es una estructura de datos bidimensional similar a una tabla en una base de datos o archivo excel, contiene columnas y filas en las que cada columna puede contener un tipo de dato diferente lo que lo hace ideal para el análisis de datos.\n",
    "Los dataframes son el corazón de Pandas.\n",
    "Crearemos un dataframe desde el csv que vamos a utilizar que es el Online_retail.csv...\n",
    "Primero veremos el método HEAD de pandas que me trae un resumen de toda la información que tengo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1    536365     71053                  WHITE METAL LANTERN         6   \n",
      "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "\n",
      "    InvoiceDate  UnitPrice  customerserID         Country  \n",
      "0  12/1/10 8:26       2.55     17850.0  United Kingdom  \n",
      "1  12/1/10 8:26       3.39     17850.0  United Kingdom  \n",
      "2  12/1/10 8:26       2.75     17850.0  United Kingdom  \n",
      "3  12/1/10 8:26       3.39     17850.0  United Kingdom  \n",
      "4  12/1/10 8:26       3.39     17850.0  United Kingdom  \n"
     ]
    }
   ],
   "source": [
    "print(retail_data.head())\n",
    "#Esta es una primera manera de crear un dataframe leyendo desde un csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame creado con Numpy (array/matriz) y Pandas(DataFrame/columnas):\n",
      "    A  B  C\n",
      "0  1  2  3\n",
      "1  4  5  6\n",
      "2  7  8  9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Crearemos un array bidimensional\n",
    "data = np.array([[1,2,3], [4,5,6], [7,8,9]])\n",
    "df_from_array = pd.DataFrame(data, columns=['A','B','C']) #Le pasamos de donde obtendrá la infromación, el nombre de las columnas que tendrá nuestro dataframe, esto claramente respecto a la dimensión que tiene nuestra matriz (dimensión 2 array)\n",
    "print('DataFrame creado con Numpy (array/matriz) y Pandas(DataFrame/columnas):\\n',df_from_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Los dataframes tambien pueden ser creados a partir de una lista o diccionario..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame from a list:\n",
      "    ID  Name  Age\n",
      "0   1  Jhon   23\n",
      "1   2   Ana   24\n",
      "Dataframe from a Dictionary:\n",
      "    ID  Name  Age\n",
      "0   1  Jhon   21\n",
      "1   2   Ana   24\n",
      "DataFrame from a Dict(columns) with List(rows):\n",
      "    ID  Name  Age\n",
      "0   1  Jhon   22\n",
      "1   2   Ana   24\n",
      "2   3  Mike   21\n"
     ]
    }
   ],
   "source": [
    "# Tendremos 3 columnas, id, name y age\n",
    "data = [[1, 'Jhon', 23], [2, 'Ana', 24]]\n",
    "df_from_list = pd.DataFrame(data, columns=['ID', 'Name', 'Age'])\n",
    "print('DataFrame from a list:\\n', df_from_list)\n",
    "\n",
    "#Con diccionarios\n",
    "#Igual tengo una lista pero ahora tendremos una clave o llave que directamente le indicaré con su valor, el primero es ID, luego el nombre con su respectivo valor y edad con su respectivo valor...\n",
    "data = [{'ID': 1,\n",
    "         'Name': 'Jhon',\n",
    "         'Age': 21},\n",
    "        {'ID': 2,\n",
    "         'Name': 'Ana',\n",
    "         'Age': 24}]\n",
    "dt_from_dict = pd.DataFrame(data) #Las columnas ya las especificamos dentro del diccionario directamente\n",
    "print('Dataframe from a Dictionary:\\n', dt_from_dict)\n",
    "\n",
    "#Ahora, puede haber el caso en el que las claves son el nombre de cada columna y cada valor que va a ir acompañado de la clave va a ser una lista...\n",
    "\n",
    "data = {'ID': [1,2,3], \n",
    "        'Name': ['Jhon', 'Ana', 'Mike'],\n",
    "        'Age': [22,24,21]}\n",
    "df_from_dict_list = pd.DataFrame(data)\n",
    "print('DataFrame from a Dict(columns) with List(rows):\\n', df_from_dict_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En pandas como bien mencionamos tenemos la herramienta principal que son los dataframes QUE SON DATOS BIDIMENSIONALES, LAS MATRICES SON BIDIMENSIONALES, pero en este caso nos referimos a tablas sin embargo, podemos descomponer dataframes en lo que sería una serie\n",
    "\n",
    "# Series\n",
    "Cada serie corresponde a una columna que equivaldría a un dato uni-dimensional, tendriamos una serie ID, nombre y edad, imagina que son las listas en el último código que hicimos..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame from Series in a Dict:\n",
      "    ID  Name  Age\n",
      "0   1  Jhon   22\n",
      "1   2   Ana   24\n",
      "2   3  Mike   21\n"
     ]
    }
   ],
   "source": [
    "#Partimos desde un diccionario que tendrá como información de filas una serie...\n",
    "data = {'ID': pd.Series([1,2,3]), \n",
    "        'Name': pd.Series(['Jhon', 'Ana', 'Mike']),\n",
    "        'Age': pd.Series([22,24,21])}\n",
    "\n",
    "df_from_series_dict = pd.DataFrame(data)\n",
    "print('DataFrame from Series in a Dict:\\n', df_from_series_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si usas Google Colab, puedes acceder a tus archivos para su lectura sin necesidad de cargarlo manualmente al contenido de Colab con el sigueinte código a partir de Google Drive:\n",
    "\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "path = \"/content/drive/My_drive/online_retail.csv\"\n",
    "\n",
    "data = pd.read_csv(path)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprender y manipular las estructuras es un proceso fundamental. El núcleo de numpy son los arrays mientras que en pandas son las series y los dataframes. Estas estructuras permiten manejar los datos de manera eficiente y realizar análisis complejos.\n",
    "\n",
    "Una serie en pandas es una estructura uni-dimensional que puede almacenar datos de cualquier tipo, similar a una columna de una tabla.\n",
    "\n",
    "Los dataframes son una estructura bidimensional similar a una tabla en una base de datos, csv o una hoja de excel.\n",
    "\n",
    "- Cuando tenemos la lectura de la información y tenemos el tipo de dato bidimensional estamos tratando con dataframes.\n",
    "\n",
    "- Cuando estamos tratando simplemente con columnas que van a ser datos unidimensionales estamos hablando de series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas de Online_ratil.csv:\n",
      " Index(['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate',\n",
      "       'UnitPrice', 'customerserID', 'Country'],\n",
      "      dtype='object')\n",
      "Número de filas:  541909\n",
      "Número de columnas:  8\n"
     ]
    }
   ],
   "source": [
    "retail_data = pd.read_csv(path, encoding='latin1')\n",
    "\n",
    "# Primero capturamos el nombre de las columnas que podemos hacer para el análisis\n",
    "columns_names = retail_data.columns\n",
    "print('Columnas de Online_ratil.csv:\\n', columns_names)\n",
    "\n",
    "#Para preguntar por la dimensión... preguntamos el numero de filas que tenemos y el numero de las columnas...\n",
    "num_rows, num_columns = retail_data.shape #Este me retorna o me da 2 elementos como respuesta, por ende creamos dos variables \n",
    "print('Número de filas: ', num_rows)\n",
    "print('Número de columnas: ', num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fila que corresponde a la columna \"Cuantity\":\n",
      " 0          6\n",
      "1          6\n",
      "2          8\n",
      "3          6\n",
      "4          6\n",
      "          ..\n",
      "541904    12\n",
      "541905     6\n",
      "541906     4\n",
      "541907     4\n",
      "541908     3\n",
      "Name: Quantity, Length: 541909, dtype: int64\n",
      "Fila 2 que corresponde a la columna \"Cuantity\":\n",
      " 8\n"
     ]
    }
   ],
   "source": [
    "daily_sales = retail_data['Quantity'] #Corresponde al nombre de la columna\n",
    "print('Fila que corresponde a la columna \"Cuantity\":\\n', daily_sales)\n",
    "\n",
    "#PUEDO ESPECIFICAR ADEMÁS UNA FILA EN CONCRETO\n",
    "print('Fila 2 que corresponde a la columna \"Cuantity\":\\n', daily_sales[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripción estadística con el método describe()\n",
    "En nuestro dataframe tambien podemos obtener una descripción estadística de cada una de las columnas que tienen información CUANTITATIVA, asi como en R, si te das cuenta son procesos que se pueden realizar en R... media, desviación estandar aplicada a una columan lo qie tengo que haces es especificar el nombre del método"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El resumen de Online Retail estadístico es:\n",
      "             Quantity      UnitPrice     customerserID\n",
      "count  541909.000000  541909.000000  406829.000000\n",
      "mean        9.552250       4.611114   15287.690570\n",
      "std       218.081158      96.759853    1713.600303\n",
      "min    -80995.000000  -11062.060000   12346.000000\n",
      "25%         1.000000       1.250000   13953.000000\n",
      "50%         3.000000       2.080000   15152.000000\n",
      "75%        10.000000       4.130000   16791.000000\n",
      "max     80995.000000   38970.000000   18287.000000\n",
      "La media de la columna especificada \"Cuantity\" es:\n",
      " 9.55224954743324\n",
      "El conteo de la columna Cuantity es:\n",
      " 541909\n"
     ]
    }
   ],
   "source": [
    "summary = retail_data.describe()\n",
    "print('El resumen de Online Retail estadístico es:\\n', summary)\n",
    "#Me dará unicamente 3 columnas ya que son las únicas en las que tenemos números\n",
    "\n",
    "\n",
    "daily_sales = retail_data['Quantity'] \n",
    "#En caso de querer ver la infromación de cada una de las columnas hacemos lo siguiente:\n",
    "mean_value_Cuantity = daily_sales.mean() #Recuerda que daily sales corresponde a una columna, por ende nos dará el promedio de esa columna que especificamos.\n",
    "print('La media de la columna especificada \"Cuantity\" es:\\n', mean_value_Cuantity)\n",
    "\n",
    "#Para obtener la suma usamos variable.sum(), para la media variable.median()\n",
    "\n",
    "#Vamos a hacer un conteo de valores de la columna Cuantity...\n",
    "count_values = daily_sales.count()\n",
    "print('El conteo de la columna Cuantity es:\\n', count_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valores nulos\n",
    "Analiza el siguiente caso de suma y conteo, es claro que cuando es una suma lo tomará el none por un 0 y cuando es un conteo este no tiene valor..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suma con valor None es:  120.0\n",
      "El conteo de la Serie dada con valor None es:  4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "daily_sales = pd.Series([10,20,None,40,50])\n",
    "#Suma\n",
    "total_sum = daily_sales.sum()\n",
    "print('Suma con valor None es: ', total_sum)\n",
    "#Conteo\n",
    "count_values = daily_sales.count()\n",
    "print('El conteo de la Serie dada con valor None es: ', count_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Método GET\n",
    "Vamos a extraer un número o filas que vamos a especificar donde por defecto tendrémos que son 5...\n",
    "\n",
    "# Consejo:\n",
    "Cuando se nos da entonces información nueva, un DataFrame que analizar lo recomendable es acceder a:\n",
    "- Conocer los encabezados, obtienes los primeras 5 filas con head()\n",
    "- Tener un resumen estadístico con describe\n",
    "- Abundar en cada columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>customerserID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>536365</td>\n",
       "      <td>85123A</td>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/10 8:26</td>\n",
       "      <td>2.55</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>536365</td>\n",
       "      <td>71053</td>\n",
       "      <td>WHITE METAL LANTERN</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/10 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>536365</td>\n",
       "      <td>84406B</td>\n",
       "      <td>CREAM CUPID HEARTS COAT HANGER</td>\n",
       "      <td>8</td>\n",
       "      <td>12/1/10 8:26</td>\n",
       "      <td>2.75</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029G</td>\n",
       "      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/10 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029E</td>\n",
       "      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/10 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>536365</td>\n",
       "      <td>22752</td>\n",
       "      <td>SET 7 BABUSHKA NESTING BOXES</td>\n",
       "      <td>2</td>\n",
       "      <td>12/1/10 8:26</td>\n",
       "      <td>7.65</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>536365</td>\n",
       "      <td>21730</td>\n",
       "      <td>GLASS STAR FROSTED T-LIGHT HOLDER</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/10 8:26</td>\n",
       "      <td>4.25</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>536366</td>\n",
       "      <td>22633</td>\n",
       "      <td>HAND WARMER UNION JACK</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/10 8:28</td>\n",
       "      <td>1.85</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  InvoiceNo StockCode                          Description  Quantity  \\\n",
       "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
       "1    536365     71053                  WHITE METAL LANTERN         6   \n",
       "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
       "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
       "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
       "5    536365     22752         SET 7 BABUSHKA NESTING BOXES         2   \n",
       "6    536365     21730    GLASS STAR FROSTED T-LIGHT HOLDER         6   \n",
       "7    536366     22633               HAND WARMER UNION JACK         6   \n",
       "\n",
       "    InvoiceDate  UnitPrice  customerserID         Country  \n",
       "0  12/1/10 8:26       2.55     17850.0  United Kingdom  \n",
       "1  12/1/10 8:26       3.39     17850.0  United Kingdom  \n",
       "2  12/1/10 8:26       2.75     17850.0  United Kingdom  \n",
       "3  12/1/10 8:26       3.39     17850.0  United Kingdom  \n",
       "4  12/1/10 8:26       3.39     17850.0  United Kingdom  \n",
       "5  12/1/10 8:26       7.65     17850.0  United Kingdom  \n",
       "6  12/1/10 8:26       4.25     17850.0  United Kingdom  \n",
       "7  12/1/10 8:28       1.85     17850.0  United Kingdom  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Primeras 5 filas\n",
    "retail_data.head()\n",
    "\n",
    "#Para obtener las primeras 8...\n",
    "retail_data.head(8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ILOC y LOC\n",
    "SELECCIÓN DE DATOS.\n",
    "\n",
    "# iloc\n",
    "Nos ayuda a extraer la información del dataframe especificando el índice que eso representa la i\n",
    "\n",
    "# loc\n",
    "Accede a la información especificando la etiqueta y esto lo haremos dando las filas y las columnas \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uso de ILOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Información de índice 0, primera fila:\n",
      " InvoiceNo                                  536365\n",
      "StockCode                                  85123A\n",
      "Description    WHITE HANGING HEART T-LIGHT HOLDER\n",
      "Quantity                                        6\n",
      "InvoiceDate                          12/1/10 8:26\n",
      "UnitPrice                                    2.55\n",
      "customerserID                                17850.0\n",
      "Country                            United Kingdom\n",
      "Name: 0, dtype: object\n",
      "Información desde el índice 0 hasta el 5\n",
      ":    InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1    536365     71053                  WHITE METAL LANTERN         6   \n",
      "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "\n",
      "    InvoiceDate  UnitPrice  customerserID         Country  \n",
      "0  12/1/10 8:26       2.55     17850.0  United Kingdom  \n",
      "1  12/1/10 8:26       3.39     17850.0  United Kingdom  \n",
      "2  12/1/10 8:26       2.75     17850.0  United Kingdom  \n",
      "3  12/1/10 8:26       3.39     17850.0  United Kingdom  \n",
      "4  12/1/10 8:26       3.39     17850.0  United Kingdom  \n"
     ]
    }
   ],
   "source": [
    "first_row = retail_data.iloc[0]\n",
    "print('Información de índice 0, primera fila:\\n', first_row)\n",
    "\n",
    "#Ahora si quiero un chunk, es decir un pedazo de información por ejemplo desde el índice 0 hasta el 5 hacemos lo siguiente\n",
    "first_five_rows = retail_data.iloc[:5]\n",
    "print('Información desde el índice 0 hasta el 5\\n: ', first_five_rows)\n",
    "\n",
    "#Recuerda que tanto las filas como las columnas inician desde 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuerda que tanto las filas como las columnas inician desde 0 y tambien puedo tener subsets de las filas y columnas... además de poder acceder a valores dentro de mi data, digamos acceder a valores de celdas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset:\n",
      "   InvoiceNo StockCode\n",
      "0    536365    85123A\n",
      "1    536365     71053\n",
      "2    536365    84406B\n",
      "Valor de celda:  WHITE METAL LANTERN\n"
     ]
    }
   ],
   "source": [
    "subset = retail_data.iloc[:3, :2] #Primero van las filas y luego las columnas, el orden normal que se ve, algebra lineal y geometría analítica\n",
    "print('Subset:\\n', subset)\n",
    "\n",
    "#Para acceder a un valor/valor de celda hacemos:\n",
    "retail_value = retail_data.iloc[1,2]\n",
    "print('Valor de celda: ', retail_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uso de LOC\n",
    "Selección de filas con LOC..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La fila 2 tiene la siguiente información:\n",
      " InvoiceNo                                   536365\n",
      "StockCode                                   84029G\n",
      "Description    KNITTED UNION FLAG HOT WATER BOTTLE\n",
      "Quantity                                         6\n",
      "InvoiceDate                           12/1/10 8:26\n",
      "UnitPrice                                     3.39\n",
      "customerserID                                 17850.0\n",
      "Country                             United Kingdom\n",
      "Name: 3, dtype: object \n",
      "\n",
      "Información de filas 0-4:\n",
      "   InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1    536365     71053                  WHITE METAL LANTERN         6   \n",
      "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "\n",
      "    InvoiceDate  UnitPrice  customerserID         Country  \n",
      "0  12/1/10 8:26       2.55     17850.0  United Kingdom  \n",
      "1  12/1/10 8:26       3.39     17850.0  United Kingdom  \n",
      "2  12/1/10 8:26       2.75     17850.0  United Kingdom  \n",
      "3  12/1/10 8:26       3.39     17850.0  United Kingdom  \n",
      "4  12/1/10 8:26       3.39     17850.0  United Kingdom   \n",
      "\n",
      "La información de inicio a fin de la columna Cuantity es:\n",
      " 0          6\n",
      "1          6\n",
      "2          8\n",
      "3          6\n",
      "4          6\n",
      "          ..\n",
      "541904    12\n",
      "541905     6\n",
      "541906     4\n",
      "541907     4\n",
      "541908     3\n",
      "Name: Quantity, Length: 541909, dtype: int64 \n",
      "\n",
      "La información de inicio a fin de la columna Cuantity Y UNITPRICE es:\n",
      "         Quantity  UnitPrice\n",
      "0              6       2.55\n",
      "1              6       3.39\n",
      "2              8       2.75\n",
      "3              6       3.39\n",
      "4              6       3.39\n",
      "...          ...        ...\n",
      "541904        12       0.85\n",
      "541905         6       2.10\n",
      "541906         4       4.15\n",
      "541907         4       4.15\n",
      "541908         3       4.95\n",
      "\n",
      "[541909 rows x 2 columns] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "row_index_3 = retail_data.loc[3]\n",
    "print('La fila 2 tiene la siguiente información:\\n', row_index_3, '\\n')\n",
    "#Chunk\n",
    "row_index_ch = retail_data.loc[:4]\n",
    "print('Información de filas 0-4:\\n', row_index_ch,'\\n')\n",
    "\n",
    "#Ahora vamos a especificar la eetiqueta/nombre de la columna con la que quiero trabajar, estamos trabajando de la misma manerea con Cuantity\n",
    "\n",
    "cuantity_columns = retail_data.loc[: , 'Quantity'] #Los argumentos son... de que fila a que fila y el nombre de la columna\n",
    "print('La información de inicio a fin de la columna Cuantity es:\\n', cuantity_columns,'\\n')\n",
    "\n",
    "#Tambien puedo hacer la selección de mas de una columna...\n",
    "cuantity_unitprices_columns = retail_data.loc[: , ['Quantity', 'UnitPrice']] #Los argumentos son... de que fila a que fila y el nombre de las columnas, FIJATE QUE LE DEBO DE PASAR UNA LISTA, no es un tercer argumento la otra columna que quiero consultar\n",
    "print('La información de inicio a fin de la columna Cuantity Y UNITPRICE es:\\n', cuantity_unitprices_columns,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consejo: Divide tu información en porciones para un mejor análisis, limpieza o extracción de información, todo depende de que es lo que quieres realizar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manejo de datos faltantes en Pandas\n",
    "Pueden surgir errores en la recolección de datos, problemas de almacenamiento o simplemente porque ciertos datos no estaban disponibles al momento del registro.\n",
    "Todo esto puede llevar a conclusiones erroneas y decisiones empresariales equivocadas.\n",
    "Existen varias maneras de corroborara que haya datos o no. Dentro de Pandas tenemos dos principales para preguntar si el dato está o no está disponible o si el dato es NULO\n",
    "Primero vamos a identificar cuales son los datos faltantes... (Que no estan disponiles) con el método isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos No dispoibles (True):\n",
      "         InvoiceNo  StockCode  Description  Quantity  InvoiceDate  UnitPrice  \\\n",
      "0           False      False        False     False        False      False   \n",
      "1           False      False        False     False        False      False   \n",
      "2           False      False        False     False        False      False   \n",
      "3           False      False        False     False        False      False   \n",
      "4           False      False        False     False        False      False   \n",
      "...           ...        ...          ...       ...          ...        ...   \n",
      "541904      False      False        False     False        False      False   \n",
      "541905      False      False        False     False        False      False   \n",
      "541906      False      False        False     False        False      False   \n",
      "541907      False      False        False     False        False      False   \n",
      "541908      False      False        False     False        False      False   \n",
      "\n",
      "        customerserID  Country  \n",
      "0            False    False  \n",
      "1            False    False  \n",
      "2            False    False  \n",
      "3            False    False  \n",
      "4            False    False  \n",
      "...            ...      ...  \n",
      "541904       False    False  \n",
      "541905       False    False  \n",
      "541906       False    False  \n",
      "541907       False    False  \n",
      "541908       False    False  \n",
      "\n",
      "[541909 rows x 8 columns]\n",
      "Primeros 5 datos:\n",
      "    InvoiceNo  StockCode  Description  Quantity  InvoiceDate  UnitPrice  \\\n",
      "0      False      False        False     False        False      False   \n",
      "1      False      False        False     False        False      False   \n",
      "2      False      False        False     False        False      False   \n",
      "3      False      False        False     False        False      False   \n",
      "4      False      False        False     False        False      False   \n",
      "\n",
      "   customerserID  Country  \n",
      "0       False    False  \n",
      "1       False    False  \n",
      "2       False    False  \n",
      "3       False    False  \n",
      "4       False    False  \n"
     ]
    }
   ],
   "source": [
    "missing_data = retail_data.isna()\n",
    "print('Datos No dispoibles (True):\\n', missing_data)\n",
    "\n",
    "#Si quiero solo los primeras 5 filas...\n",
    "print('Primeros 5 datos:\\n', missing_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quiero contar cuantos datos faltantes tenemos, pues tenemos varias filas de información y lo que nos queda es indigar por columna o fila\n",
    "\n",
    "Ya que una vez sabiendo si hay datos faltantes o no dentro de nuestro set de datos tenemos dos opciones principales...\n",
    "- Eliminar esas filas o campos donde esta nulo\n",
    "- Llenar estos valores haciendo un cambio\n",
    "\n",
    "# dropna()\n",
    "Hay que tener cuidado pues si hay con tan solo un elemento dentro de la columna sin información o no esta diponible este método de la igual forma LO ELIMINARÁ.\n",
    "\n",
    "Hay más tratamientos que podríamos aplicar..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteo de datos faltantes por columna:\n",
      " InvoiceNo           0\n",
      "StockCode           0\n",
      "Description      1454\n",
      "Quantity            0\n",
      "InvoiceDate         0\n",
      "UnitPrice           0\n",
      "customerserID     135080\n",
      "Country             0\n",
      "dtype: int64 \n",
      "\n",
      "Eliminar esa información NO disponible... (FILAS)\n",
      "\n",
      "Información completa, se eliminaron las filas sin información:\n",
      "        InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0         536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1         536365     71053                  WHITE METAL LANTERN         6   \n",
      "2         536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3         536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4         536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "...          ...       ...                                  ...       ...   \n",
      "541904    581587     22613          PACK OF 20 SPACEBOY NAPKINS        12   \n",
      "541905    581587     22899         CHILDREN'S APRON DOLLY GIRL          6   \n",
      "541906    581587     23254        CHILDRENS CUTLERY DOLLY GIRL          4   \n",
      "541907    581587     23255      CHILDRENS CUTLERY CIRCUS PARADE         4   \n",
      "541908    581587     22138        BAKING SET 9 PIECE RETROSPOT          3   \n",
      "\n",
      "          InvoiceDate  UnitPrice  customerserID         Country  \n",
      "0        12/1/10 8:26       2.55     17850.0  United Kingdom  \n",
      "1        12/1/10 8:26       3.39     17850.0  United Kingdom  \n",
      "2        12/1/10 8:26       2.75     17850.0  United Kingdom  \n",
      "3        12/1/10 8:26       3.39     17850.0  United Kingdom  \n",
      "4        12/1/10 8:26       3.39     17850.0  United Kingdom  \n",
      "...               ...        ...         ...             ...  \n",
      "541904  12/9/11 12:50       0.85     12680.0          France  \n",
      "541905  12/9/11 12:50       2.10     12680.0          France  \n",
      "541906  12/9/11 12:50       4.15     12680.0          France  \n",
      "541907  12/9/11 12:50       4.15     12680.0          France  \n",
      "541908  12/9/11 12:50       4.95     12680.0          France  \n",
      "\n",
      "[406829 rows x 8 columns]\n",
      "\n",
      "Agregar información faltante con 0...\n",
      "\n",
      "Información completa de Online Retail con valores 0 en donde no había disponibilidad de datos:\n",
      "        InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0         536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1         536365     71053                  WHITE METAL LANTERN         6   \n",
      "2         536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3         536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4         536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "...          ...       ...                                  ...       ...   \n",
      "541904    581587     22613          PACK OF 20 SPACEBOY NAPKINS        12   \n",
      "541905    581587     22899         CHILDREN'S APRON DOLLY GIRL          6   \n",
      "541906    581587     23254        CHILDRENS CUTLERY DOLLY GIRL          4   \n",
      "541907    581587     23255      CHILDRENS CUTLERY CIRCUS PARADE         4   \n",
      "541908    581587     22138        BAKING SET 9 PIECE RETROSPOT          3   \n",
      "\n",
      "          InvoiceDate  UnitPrice  customerserID         Country  \n",
      "0        12/1/10 8:26       2.55     17850.0  United Kingdom  \n",
      "1        12/1/10 8:26       3.39     17850.0  United Kingdom  \n",
      "2        12/1/10 8:26       2.75     17850.0  United Kingdom  \n",
      "3        12/1/10 8:26       3.39     17850.0  United Kingdom  \n",
      "4        12/1/10 8:26       3.39     17850.0  United Kingdom  \n",
      "...               ...        ...         ...             ...  \n",
      "541904  12/9/11 12:50       0.85     12680.0          France  \n",
      "541905  12/9/11 12:50       2.10     12680.0          France  \n",
      "541906  12/9/11 12:50       4.15     12680.0          France  \n",
      "541907  12/9/11 12:50       4.15     12680.0          France  \n",
      "541908  12/9/11 12:50       4.95     12680.0          France  \n",
      "\n",
      "[541909 rows x 8 columns]\n",
      "\n",
      "Accedemos de nuevo a la suma de valores con entrada None o NO disponible...\n",
      "\n",
      "Suma de datos faltantes después de proceso de relleno:\n",
      " InvoiceNo      0\n",
      "StockCode      0\n",
      "Description    0\n",
      "Quantity       0\n",
      "InvoiceDate    0\n",
      "UnitPrice      0\n",
      "customerserID     0\n",
      "Country        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_data_count = retail_data.isna().sum()\n",
    "#El conteo lo realiza por COLUMNA\n",
    "print('Conteo de datos faltantes por columna:\\n', missing_data_count, '\\n')\n",
    "\n",
    "print('Eliminar esa información NO disponible... (FILAS)\\n')\n",
    "#Queremos acceder a los datos que no se estan perdiendo...\n",
    "no_missing_rows = retail_data.dropna()\n",
    "print('Información completa, se eliminaron las filas sin información:\\n', no_missing_rows)\n",
    "\n",
    "print('\\nAgregar información faltante con 0...\\n')\n",
    "retail_data_filled_zeros = retail_data.fillna(0)\n",
    "print('Información completa de Online Retail con valores 0 en donde no había disponibilidad de datos:\\n', retail_data_filled_zeros)\n",
    "\n",
    "print('\\nAccedemos de nuevo a la suma de valores con entrada None o NO disponible...\\n')\n",
    "print('Suma de datos faltantes después de proceso de relleno:\\n', retail_data_filled_zeros.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos llenar los datos faltantes pero con térnicas estadísticas como bien lo pueden ser hallar la media de la columna y en los datos que no tenemos insertarlos ahí para no tener una modificación más grande."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columna UnitPrices rellena en campos faltantes con la media de la columna:\n",
      " 0         2.55\n",
      "1         3.39\n",
      "2         2.75\n",
      "3         3.39\n",
      "4         3.39\n",
      "          ... \n",
      "541904    0.85\n",
      "541905    2.10\n",
      "541906    4.15\n",
      "541907    4.15\n",
      "541908    4.95\n",
      "Name: UnitPrice, Length: 541909, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "mean_unit_price = retail_data['UnitPrice'].mean()\n",
    "retail_column_filled_mean = retail_data['UnitPrice'].fillna(mean_unit_price)\n",
    "print('Columna UnitPrices rellena en campos faltantes con la media de la columna:\\n', retail_column_filled_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulación de columnas \n",
    "En este caso veremos la creación de columnas, esto lo haremos a partir de:\n",
    "- Dos columnas de nuestro dataframe (operaciones entre ellas)\n",
    "- A travéz de condicionales con valores de tipo booleano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1    536365     71053                  WHITE METAL LANTERN         6   \n",
      "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "\n",
      "    InvoiceDate  UnitPrice  customerserID         Country  TotalPrice  \n",
      "0  12/1/10 8:26       2.55     17850.0  United Kingdom       15.30  \n",
      "1  12/1/10 8:26       3.39     17850.0  United Kingdom       20.34  \n",
      "2  12/1/10 8:26       2.75     17850.0  United Kingdom       22.00  \n",
      "3  12/1/10 8:26       3.39     17850.0  United Kingdom       20.34  \n",
      "4  12/1/10 8:26       3.39     17850.0  United Kingdom       20.34  \n",
      "0    False\n",
      "1     True\n",
      "2     True\n",
      "3     True\n",
      "4     True\n",
      "5    False\n",
      "6     True\n",
      "7    False\n",
      "8    False\n",
      "9     True\n",
      "Name: HighValue, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/hectorastudillo/py-proyects/data-analysis/pandas/Online_Retail.csv', encoding='latin1') \n",
    "\n",
    "\n",
    "df['TotalPrice'] = df['Quantity'] * df['UnitPrice'] #Con ello ya está añadido la nueva columna\n",
    "print(df.head()) #Observamos las primeras 5 filas\n",
    "\n",
    "df['HighValue'] = df['TotalPrice'] > 16\n",
    "print(df['HighValue'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas por defecto captura el tipo de dato que tiene cada columna y esto puede ir variando a menos que nosotros le especifiquemos, para ello podemos obtener información a partir del método info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 541909 entries, 0 to 541908\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   InvoiceNo    541909 non-null  object \n",
      " 1   StockCode    541909 non-null  object \n",
      " 2   Description  540455 non-null  object \n",
      " 3   Quantity     541909 non-null  int64  \n",
      " 4   InvoiceDate  541909 non-null  object \n",
      " 5   UnitPrice    541909 non-null  float64\n",
      " 6   customerserID   406829 non-null  float64\n",
      " 7   Country      541909 non-null  object \n",
      " 8   TotalPrice   541909 non-null  float64\n",
      " 9   HighValue    541909 non-null  bool   \n",
      "dtypes: bool(1), float64(3), int64(1), object(5)\n",
      "memory usage: 37.7+ MB\n",
      "Información del DataFrame:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kz/rybrs64563zc2gl94rf00qbw0000gn/T/ipykernel_4458/2528066143.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate']) #Sobre que columna se hará el cambio o que columna se creará. Luego va que columna se ve involucrada, de donde tomará la información digamos. En este caso es un cambio sobre una columna ya existente en ell dataframe y su misma información.\n"
     ]
    }
   ],
   "source": [
    "print('Información del DataFrame:\\n', df.info())\n",
    "#Trabajaremos en este caso con InvoiceDate que pandas lo identifica que es de tipo object, sin embargo especificaremos que es de tipo Date para una mejor manipulación\n",
    "\n",
    "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate']) #Sobre que columna se hará el cambio o que columna se creará. Luego va que columna se ve involucrada, de donde tomará la información digamos. En este caso es un cambio sobre una columna ya existente en ell dataframe y su misma información.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda\n",
    "En pandas tambien podemos aplicar la función lambda pero en este caso aplicará a cada una de las columnas la operación que nosotros vamos a especificar...\n",
    "Vamos a crear otra columna que aplicará lambda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1    536365     71053                  WHITE METAL LANTERN         6   \n",
      "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "\n",
      "          InvoiceDate  UnitPrice  customerserID         Country  TotalPrice  \\\n",
      "0 2010-12-01 08:26:00       2.55     17850.0  United Kingdom       15.30   \n",
      "1 2010-12-01 08:26:00       3.39     17850.0  United Kingdom       20.34   \n",
      "2 2010-12-01 08:26:00       2.75     17850.0  United Kingdom       22.00   \n",
      "3 2010-12-01 08:26:00       3.39     17850.0  United Kingdom       20.34   \n",
      "4 2010-12-01 08:26:00       3.39     17850.0  United Kingdom       20.34   \n",
      "\n",
      "   HighValue  DiscountPrice  \n",
      "0      False          2.295  \n",
      "1       True          3.051  \n",
      "2       True          2.475  \n",
      "3       True          3.051  \n",
      "4       True          3.051  \n"
     ]
    }
   ],
   "source": [
    "df['DiscountPrice'] = df['UnitPrice'].apply(lambda x : x*0.9)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambien podemos aplicar una función a cada una de nuestras filas también utilizando el método apply, ten encunta que podemos tener transformaciones con datos categóricos y no solo numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1    536365     71053                  WHITE METAL LANTERN         6   \n",
      "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "\n",
      "          InvoiceDate  UnitPrice  customerserID         Country  TotalPrice  \\\n",
      "0 2010-12-01 08:26:00       2.55     17850.0  United Kingdom       15.30   \n",
      "1 2010-12-01 08:26:00       3.39     17850.0  United Kingdom       20.34   \n",
      "2 2010-12-01 08:26:00       2.75     17850.0  United Kingdom       22.00   \n",
      "3 2010-12-01 08:26:00       3.39     17850.0  United Kingdom       20.34   \n",
      "4 2010-12-01 08:26:00       3.39     17850.0  United Kingdom       20.34   \n",
      "\n",
      "   HighValue  DiscountPrice PriceCategory  \n",
      "0      False          2.295        Medium  \n",
      "1       True          3.051        Medium  \n",
      "2       True          2.475        Medium  \n",
      "3       True          3.051        Medium  \n",
      "4       True          3.051        Medium  \n"
     ]
    }
   ],
   "source": [
    "def categorize_price(price): #Para cada uno de los UnitPrices lo que haremos es categorizar de la siguiente manera:\n",
    "    if price > 50:\n",
    "        return 'High'\n",
    "    elif price < 20:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'Low'\n",
    "    \n",
    "#Como esa función queremos aplciarlo a nuestro dataframe hacemos lo siguiente:\n",
    "df['PriceCategory'] = df['UnitPrice'].apply(categorize_price) \n",
    "#Recuerda, sobre que columna se aplicará la información o de no existir se crea. Luego va de que columna tomará la información.\n",
    "print(df.head()) #Obtenemos las primeras 5 filas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agrupaciones con GroupBy\n",
    "Imagina que eres un analista de ventas, en este caso agruparemos nuestra información en distintas secciones de nuestro interes para posteriormente aplicar operaciones estadísticas que nos ayudarán a conocer la venta de los productos dentro de cada sección.\n",
    "\n",
    "Esto lo lograremos con el método groupby\n",
    "Primeramente vamos a ver un método para obtener la distribución de frecuencias de la columna \"Country\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ventas de cada país:\n",
      " Country\n",
      "United Kingdom          495478\n",
      "Germany                   9495\n",
      "France                    8557\n",
      "EIRE                      8196\n",
      "Spain                     2533\n",
      "Netherlands               2371\n",
      "Belgium                   2069\n",
      "Switzerland               2002\n",
      "Portugal                  1519\n",
      "Australia                 1259\n",
      "Norway                    1086\n",
      "Italy                      803\n",
      "Channel Islands            758\n",
      "Finland                    695\n",
      "Cyprus                     622\n",
      "Sweden                     462\n",
      "Unspecified                446\n",
      "Austria                    401\n",
      "Denmark                    389\n",
      "Japan                      358\n",
      "Poland                     341\n",
      "Israel                     297\n",
      "USA                        291\n",
      "Hong Kong                  288\n",
      "Singapore                  229\n",
      "Iceland                    182\n",
      "Canada                     151\n",
      "Greece                     146\n",
      "Malta                      127\n",
      "United Arab Emirates        68\n",
      "European Community          61\n",
      "RSA                         58\n",
      "Lebanon                     45\n",
      "Lithuania                   35\n",
      "Brazil                      32\n",
      "Czech Republic              30\n",
      "Bahrain                     19\n",
      "Saudi Arabia                10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "country_count = df['Country'].value_counts()\n",
    "print('Ventas de cada país:\\n', country_count)\n",
    "#Lo que hace value_counts es agarrar cada uno de los VALORES ÚNICOS y sumarlos realizando un conteo de todos estos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ir más allá y especificar ahora alguna acción que queramos hacer con la grupación de las columnas.\n",
    "\n",
    "Ahora haremos un agrupamiento por país pero para calcular la suma total que tiene la columna cantidad..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paises con la suma total de ventas\n",
      " Country\n",
      "Australia                 83653\n",
      "Austria                    4827\n",
      "Bahrain                     260\n",
      "Belgium                   23152\n",
      "Brazil                      356\n",
      "Canada                     2763\n",
      "Channel Islands            9479\n",
      "Cyprus                     6317\n",
      "Czech Republic              592\n",
      "Denmark                    8188\n",
      "EIRE                     142637\n",
      "European Community          497\n",
      "Finland                   10666\n",
      "France                   110480\n",
      "Germany                  117448\n",
      "Greece                     1556\n",
      "Hong Kong                  4769\n",
      "Iceland                    2458\n",
      "Israel                     4353\n",
      "Italy                      7999\n",
      "Japan                     25218\n",
      "Lebanon                     386\n",
      "Lithuania                   652\n",
      "Malta                       944\n",
      "Netherlands              200128\n",
      "Norway                    19247\n",
      "Poland                     3653\n",
      "Portugal                  16180\n",
      "RSA                         352\n",
      "Saudi Arabia                 75\n",
      "Singapore                  5234\n",
      "Spain                     26824\n",
      "Sweden                    35637\n",
      "Switzerland               30325\n",
      "USA                        1034\n",
      "United Arab Emirates        982\n",
      "United Kingdom          4263829\n",
      "Unspecified                3300\n",
      "Name: Quantity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "country_group = df.groupby('Country')['Quantity'].sum()\n",
    "#Queremos agrupar los paises \n",
    "#De cada país vamos a extraer la Cantidad de ventas que se esta haciendo en esta tienda, osea que información usará\n",
    "#De cada país vamos a obtener la suma... es la operación que se aplica\n",
    "print('Paises con la suma total de ventas\\n', country_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general como te has dado cuenta primero le indicamos la columna a trabajar o crear, en este caso estamos trabajando con la columna Country, de ahí le pasamos la información que manejará, en este caso la información será obtenida de Quantity y por último la operación a aplicar.\n",
    "\n",
    "Haciendo esta agrupación tambien podemos aplicar operaciones estadísticas, es decir para este ejemplo, para cada pais tambien podemos obtener la media, mediana,etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats of each Country:\n",
      "                             mean          sum\n",
      "Country                                      \n",
      "Australia               3.220612     4054.750\n",
      "Austria                 4.243192     1701.520\n",
      "Bahrain                 4.556316       86.570\n",
      "Belgium                 3.644335     7540.130\n",
      "Brazil                  4.456250      142.600\n",
      "Canada                  6.030331      910.580\n",
      "Channel Islands         4.932124     3738.550\n",
      "Cyprus                  6.302363     3920.070\n",
      "Czech Republic          2.938333       88.150\n",
      "Denmark                 3.256941     1266.950\n",
      "EIRE                    5.911077    48447.190\n",
      "European Community      4.820492      294.050\n",
      "Finland                 5.448705     3786.850\n",
      "France                  5.028864    43031.990\n",
      "Germany                 3.966930    37666.000\n",
      "Greece                  4.885548      713.290\n",
      "Hong Kong              42.505208    12241.500\n",
      "Iceland                 2.644011      481.210\n",
      "Israel                  3.633131     1079.040\n",
      "Italy                   4.831121     3879.390\n",
      "Japan                   2.276145      814.860\n",
      "Lebanon                 5.387556      242.440\n",
      "Lithuania               2.841143       99.440\n",
      "Malta                   5.244173      666.010\n",
      "Netherlands             2.738317     6492.550\n",
      "Norway                  6.012026     6529.060\n",
      "Poland                  4.170880     1422.270\n",
      "Portugal                8.582976    13037.540\n",
      "RSA                     4.277586      248.100\n",
      "Saudi Arabia            2.411000       24.110\n",
      "Singapore             109.645808    25108.890\n",
      "Spain                   4.987544    12633.450\n",
      "Sweden                  3.910887     1806.830\n",
      "Switzerland             3.403442     6813.690\n",
      "USA                     2.216426      644.980\n",
      "United Arab Emirates    3.380735      229.890\n",
      "United Kingdom          4.532422  2245715.474\n",
      "Unspecified             2.699574     1204.010\n"
     ]
    }
   ],
   "source": [
    "country_stats = df.groupby(['Country'])['UnitPrice'].agg(['mean', 'sum'])\n",
    "print('Stats of each Country:\\n', country_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra cosa que podemos hacer es agrupaciones digamos múltiples de una columna respecto a otra, por ejemplo puedo agruparlos por país y dentro de cada país además agruparlos por Código de Stock, esto se enviará en formato de lista:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paises agrupados por códigos de stock:\n",
      " Country      StockCode\n",
      "Australia    15036        600\n",
      "             15056BL        3\n",
      "             16161P       400\n",
      "             16169E        25\n",
      "             20665          6\n",
      "                         ... \n",
      "Unspecified  85180A         2\n",
      "             85180B         1\n",
      "             85212         12\n",
      "             85213         12\n",
      "             85227         10\n",
      "Name: Quantity, Length: 19839, dtype: int64\n",
      "\n",
      "Otro ejemplo de agrupación creado con una función, (analiza su sintaxis):\n",
      "\n",
      "Total de ventas por país ($):\n",
      " Country\n",
      "Australia                137077.270\n",
      "Austria                   10154.320\n",
      "Bahrain                     548.400\n",
      "Belgium                   40910.960\n",
      "Brazil                     1143.600\n",
      "Canada                     3666.380\n",
      "Channel Islands           20086.290\n",
      "Cyprus                    12946.290\n",
      "Czech Republic              707.720\n",
      "Denmark                   18768.140\n",
      "EIRE                     263276.820\n",
      "European Community         1291.750\n",
      "Finland                   22326.740\n",
      "France                   197403.900\n",
      "Germany                  221698.210\n",
      "Greece                     4710.520\n",
      "Hong Kong                 10117.040\n",
      "Iceland                    4310.000\n",
      "Israel                     7907.820\n",
      "Italy                     16890.510\n",
      "Japan                     35340.620\n",
      "Lebanon                    1693.880\n",
      "Lithuania                  1661.060\n",
      "Malta                      2505.470\n",
      "Netherlands              284661.540\n",
      "Norway                    35163.460\n",
      "Poland                     7213.140\n",
      "Portugal                  29367.020\n",
      "RSA                        1002.310\n",
      "Saudi Arabia                131.170\n",
      "Singapore                  9120.390\n",
      "Spain                     54774.580\n",
      "Sweden                    36595.910\n",
      "Switzerland               56385.350\n",
      "USA                        1730.920\n",
      "United Arab Emirates       1902.280\n",
      "United Kingdom          8187806.364\n",
      "Unspecified                4749.790\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kz/rybrs64563zc2gl94rf00qbw0000gn/T/ipykernel_4458/4246130189.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  revenue_per_country = df.groupby('Country').apply(total_revenue)\n"
     ]
    }
   ],
   "source": [
    "country_stock_group = df.groupby(['Country', 'StockCode'])['Quantity'].sum()\n",
    "print('Paises agrupados por códigos de stock:\\n', country_stock_group)\n",
    "\n",
    "\n",
    "print('\\nOtro ejemplo de agrupación creado con una función, (analiza su sintaxis):\\n')\n",
    "#Ahora obtendremos el revenue total o ganancia por cada país, esto lo realizaremos con una función\n",
    "def total_revenue(group): #Con group categorizamos\n",
    "    return (group['Quantity'] * group['UnitPrice']).sum() #Multiplica la cantidad por la unidad de precio que se vendió y sumalas, simplemente.\n",
    "\n",
    "revenue_per_country = df.groupby('Country').apply(total_revenue) \n",
    "#Primero indicamos que lo agrupe por pais (groupby)\n",
    "#Luego le pasamos la operación a aplicar, en este caso estamos damos uso de una función que creamos.\n",
    "print('Total de ventas por país ($):\\n', revenue_per_country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtrado de datos\n",
    "Es una técnica que nos permite extraer subconjuntos específicos de información basandonos en condiciones lógicas lo cual es fundamental en el análisis de datos, imaginate poder enfocarte solo en las ventas de un país específico, analizar productos que superan o no cierta cantidad de ventas o analizar las transacciones realizadas durante un periodo de tiempo, todo esto nos ayudará a centrarnos en lo que nos interesa, hacerlo más simple y prestar atención en datos específicos de nuestro set de datos y poder hacer así un tratamiento para poder calcular ventas por ciertos paises o series de tiempo que veremos más delante.\n",
    "\n",
    "\n",
    "- Si por ejemplo queremos filtrar las ventas en un país específico como Reino Unido\n",
    "- Con el filtrado tambien podemmos preguntar si un valor es mayor o menor que otro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrado por país\n",
      "\n",
      "Ventas que solo se han hecho en UK:\n",
      "        InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0         536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1         536365     71053                  WHITE METAL LANTERN         6   \n",
      "2         536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3         536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4         536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "...          ...       ...                                  ...       ...   \n",
      "541889    581585     22466       FAIRY TALE COTTAGE NIGHT LIGHT        12   \n",
      "541890    581586     22061  LARGE CAKE STAND  HANGING STRAWBERY         8   \n",
      "541891    581586     23275     SET OF 3 HANGING OWLS OLLIE BEAK        24   \n",
      "541892    581586     21217        RED RETROSPOT ROUND CAKE TINS        24   \n",
      "541893    581586     20685                DOORMAT RED RETROSPOT        10   \n",
      "\n",
      "          InvoiceDate  UnitPrice  customerserID         Country  \n",
      "0        12/1/10 8:26       2.55     17850.0  United Kingdom  \n",
      "1        12/1/10 8:26       3.39     17850.0  United Kingdom  \n",
      "2        12/1/10 8:26       2.75     17850.0  United Kingdom  \n",
      "3        12/1/10 8:26       3.39     17850.0  United Kingdom  \n",
      "4        12/1/10 8:26       3.39     17850.0  United Kingdom  \n",
      "...               ...        ...         ...             ...  \n",
      "541889  12/9/11 12:31       1.95     15804.0  United Kingdom  \n",
      "541890  12/9/11 12:49       2.95     13113.0  United Kingdom  \n",
      "541891  12/9/11 12:49       1.25     13113.0  United Kingdom  \n",
      "541892  12/9/11 12:49       8.95     13113.0  United Kingdom  \n",
      "541893  12/9/11 12:49       7.08     13113.0  United Kingdom  \n",
      "\n",
      "[495478 rows x 8 columns]\n",
      "\n",
      "Filtrado con conidicionales\n",
      "\n",
      "Ventas mayores a 10 (se nos indican las filas):\n",
      "        InvoiceNo StockCode                      Description  Quantity  \\\n",
      "9         536367     84879    ASSORTED COLOUR BIRD ORNAMENT        32   \n",
      "26        536370     22728        ALARM CLOCK BAKELIKE PINK        24   \n",
      "27        536370     22727        ALARM CLOCK BAKELIKE RED         24   \n",
      "28        536370     22726       ALARM CLOCK BAKELIKE GREEN        12   \n",
      "29        536370     21724  PANDA AND BUNNIES STICKER SHEET        12   \n",
      "...          ...       ...                              ...       ...   \n",
      "541894    581587     22631         CIRCUS PARADE LUNCH BOX         12   \n",
      "541895    581587     22556   PLASTERS IN TIN CIRCUS PARADE         12   \n",
      "541896    581587     22555        PLASTERS IN TIN STRONGMAN        12   \n",
      "541902    581587     22629              SPACEBOY LUNCH BOX         12   \n",
      "541904    581587     22613      PACK OF 20 SPACEBOY NAPKINS        12   \n",
      "\n",
      "          InvoiceDate  UnitPrice  customerserID         Country  \n",
      "9        12/1/10 8:34       1.69     13047.0  United Kingdom  \n",
      "26       12/1/10 8:45       3.75     12583.0          France  \n",
      "27       12/1/10 8:45       3.75     12583.0          France  \n",
      "28       12/1/10 8:45       3.75     12583.0          France  \n",
      "29       12/1/10 8:45       0.85     12583.0          France  \n",
      "...               ...        ...         ...             ...  \n",
      "541894  12/9/11 12:50       1.95     12680.0          France  \n",
      "541895  12/9/11 12:50       1.65     12680.0          France  \n",
      "541896  12/9/11 12:50       1.65     12680.0          France  \n",
      "541902  12/9/11 12:50       1.95     12680.0          France  \n",
      "541904  12/9/11 12:50       0.85     12680.0          France  \n",
      "\n",
      "[132631 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print('Filtrado por país\\n')\n",
    "retail_data_filled_zeros = retail_data.fillna(0)\n",
    "#Filtrar ventas en el Reino Unido - UK\n",
    "uk_sales = retail_data_filled_zeros[retail_data_filled_zeros['Country'] == 'United Kingdom']\n",
    "#Primero va, de donde sacaré toda mi información, en este caso recuerda que creamos una variable en donde rellenamos los datos NO disponibles con ceros\n",
    "#De esa información voy a trabajar con una columna en específico Y SOLO TOMARÁ ESA INFORMACIÓN CUANDO ES IGUAL A UNITED KINGDOM\n",
    "print('Ventas que solo se han hecho en UK:\\n', uk_sales)\n",
    "\n",
    "print('\\nFiltrado con conidicionales\\n')\n",
    "#Ahora vamos a filtrar las ventas donde la cantidad sea mayor a un número\n",
    "high_sales = retail_data_filled_zeros[retail_data_filled_zeros['Quantity'] > 10]\n",
    "print('Ventas mayores a 10 (se nos indican las filas):\\n', high_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a ver como hacer este filtrado en una sola linea de codiga para pdoer evaluar ambas filtraciones... ahora queremos las ventas altas de UK en la columna Cantidad de ventas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrado con condicional (&), presta atención a la sintaxis:\n",
      "        InvoiceNo StockCode                          Description  Quantity  \\\n",
      "46        536371     22086      PAPER CHAIN KIT 50'S CHRISTMAS         80   \n",
      "82        536376     22114    HOT WATER BOTTLE TEA AND SYMPATHY        48   \n",
      "83        536376     21733     RED HANGING HEART T-LIGHT HOLDER        64   \n",
      "96        536378     21212      PACK OF 72 RETROSPOT CAKE CASES       120   \n",
      "101       536378    85183B  CHARLIE & LOLA WASTEPAPER BIN FLORA        48   \n",
      "...          ...       ...                                  ...       ...   \n",
      "541746    581571     23167       SMALL CERAMIC TOP STORAGE JAR         96   \n",
      "541747    581571     21314        SMALL GLASS HEART TRINKET POT        48   \n",
      "541751    581572     23328   SET 6 SCHOOL MILK BOTTLES IN CRATE        48   \n",
      "541867    581584     20832     RED FLOCK LOVE HEART PHOTO FRAME        72   \n",
      "541868    581584     85038      6 CHOCOLATE LOVE HEART T-LIGHTS        48   \n",
      "\n",
      "          InvoiceDate  UnitPrice  customerserID         Country  \n",
      "46       12/1/10 9:00       2.55     13748.0  United Kingdom  \n",
      "82       12/1/10 9:32       3.45     15291.0  United Kingdom  \n",
      "83       12/1/10 9:32       2.55     15291.0  United Kingdom  \n",
      "96       12/1/10 9:37       0.42     14688.0  United Kingdom  \n",
      "101      12/1/10 9:37       1.25     14688.0  United Kingdom  \n",
      "...               ...        ...         ...             ...  \n",
      "541746  12/9/11 12:00       0.69     15311.0  United Kingdom  \n",
      "541747  12/9/11 12:00       1.85     15311.0  United Kingdom  \n",
      "541751  12/9/11 12:08       3.39     16705.0  United Kingdom  \n",
      "541867  12/9/11 12:25       0.72     13777.0  United Kingdom  \n",
      "541868  12/9/11 12:25       1.85     13777.0  United Kingdom  \n",
      "\n",
      "[15179 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "uk_high_quantity_sales = retail_data_filled_zeros[(\n",
    "    retail_data_filled_zeros['Country'] == 'United Kingdom') & \n",
    "    (retail_data_filled_zeros['Quantity'] > 40)]\n",
    "#Vamos a evaluar primero el country, igual a UK Y ADEMÁS QUEREMOS evaluar que la cantidad sea mayor a 40, no debería haber problema con los operadores, quizá con la sintaxis simplemente.\n",
    "print('Filtrado con condicional (&), presta atención a la sintaxis:\\n', uk_high_quantity_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer una filtración pero ahora especificando el año en esta serie. Filtración de ventas del año 2011.\n",
    "\n",
    "El problema es que dentro de retail_data aún no tenemos transformada la columna de InvoiceDate a tipo Date, por ende nos saldrá un eror.\n",
    "\n",
    "Bueno al parecer si ya lo habíamos hecho, el punto es tener en cuenta eso y especificar el formato el cual tiene los datos la columna en tipo date, esto solo para mejor eficiencia en el código.\n",
    "\n",
    "Posterior a la filtración por año 2011, haremos una filtración por mes (1-12) y por año."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Información de 2011:\n",
      "        InvoiceNo StockCode                      Description  Quantity  \\\n",
      "42481     539993     22386          JUMBO BAG PINK POLKADOT        10   \n",
      "42482     539993     21499               BLUE POLKADOT WRAP        25   \n",
      "42483     539993     21498              RED RETROSPOT WRAP         25   \n",
      "42484     539993     22379         RECYCLING BAG RETROSPOT          5   \n",
      "42485     539993     20718        RED RETROSPOT SHOPPER BAG        10   \n",
      "...          ...       ...                              ...       ...   \n",
      "541904    581587     22613      PACK OF 20 SPACEBOY NAPKINS        12   \n",
      "541905    581587     22899     CHILDREN'S APRON DOLLY GIRL          6   \n",
      "541906    581587     23254    CHILDRENS CUTLERY DOLLY GIRL          4   \n",
      "541907    581587     23255  CHILDRENS CUTLERY CIRCUS PARADE         4   \n",
      "541908    581587     22138    BAKING SET 9 PIECE RETROSPOT          3   \n",
      "\n",
      "               InvoiceDate  UnitPrice  customerserID         Country  \n",
      "42481  2011-01-04 10:00:00       1.95     13313.0  United Kingdom  \n",
      "42482  2011-01-04 10:00:00       0.42     13313.0  United Kingdom  \n",
      "42483  2011-01-04 10:00:00       0.42     13313.0  United Kingdom  \n",
      "42484  2011-01-04 10:00:00       2.10     13313.0  United Kingdom  \n",
      "42485  2011-01-04 10:00:00       1.25     13313.0  United Kingdom  \n",
      "...                    ...        ...         ...             ...  \n",
      "541904 2011-12-09 12:50:00       0.85     12680.0          France  \n",
      "541905 2011-12-09 12:50:00       2.10     12680.0          France  \n",
      "541906 2011-12-09 12:50:00       4.15     12680.0          France  \n",
      "541907 2011-12-09 12:50:00       4.15     12680.0          France  \n",
      "541908 2011-12-09 12:50:00       4.95     12680.0          France  \n",
      "\n",
      "[499428 rows x 8 columns]\n",
      "\n",
      "Dos filtraciones - Mes y Año:\n",
      "\n",
      "      InvoiceNo StockCode                          Description  Quantity  \\\n",
      "0        536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1        536365     71053                  WHITE METAL LANTERN         6   \n",
      "2        536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3        536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4        536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "...         ...       ...                                  ...       ...   \n",
      "42476    539991     21618       4 WILDFLOWER BOTANICAL CANDLES         1   \n",
      "42477    539991     72741                GRAND CHOCOLATECANDLE         4   \n",
      "42478    539992     21470        FLOWER VINE RAFFIA FOOD COVER         1   \n",
      "42479    539992     22258              FELT FARM ANIMAL RABBIT         1   \n",
      "42480    539992     21155                RED RETROSPOT PEG BAG         1   \n",
      "\n",
      "              InvoiceDate  UnitPrice  customerserID         Country  \n",
      "0     2010-12-01 08:26:00       2.55     17850.0  United Kingdom  \n",
      "1     2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
      "2     2010-12-01 08:26:00       2.75     17850.0  United Kingdom  \n",
      "3     2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
      "4     2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
      "...                   ...        ...         ...             ...  \n",
      "42476 2010-12-23 16:49:00       1.25         NaN  United Kingdom  \n",
      "42477 2010-12-23 16:49:00       1.45         NaN  United Kingdom  \n",
      "42478 2010-12-23 17:41:00       3.75         NaN  United Kingdom  \n",
      "42479 2010-12-23 17:41:00       1.25         NaN  United Kingdom  \n",
      "42480 2010-12-23 17:41:00       2.10         NaN  United Kingdom  \n",
      "\n",
      "[42481 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "retail_data['InvoiceDate'] = pd.to_datetime(retail_data['InvoiceDate'], format='%m/%d/%y %H:%M', errors='coerce')\n",
    "\n",
    "sales_2011 = retail_data[retail_data['InvoiceDate'].dt.year == 2011]\n",
    "#Quiero extraer de mi dt el año y luego le indico que valor va a extraer, en este caso queremos el año 2011\n",
    "print('Información de 2011:\\n', sales_2011)\n",
    "\n",
    "print('\\nDos filtraciones - Mes y Año:\\n')\n",
    "sales_month_year = retail_data[(\n",
    "    retail_data['InvoiceDate'].dt.year == 2010) & (retail_data['InvoiceDate'].dt.month == 12)]\n",
    "print(sales_month_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivot Tables\n",
    "Permite resumir y reorganizar columnas de datos crudos con dataframes de pandas con el podemos realizar operaciones como sumas, promedios,etc. Ello nos ayuda a encontrar patrones e insights que de otro modo podrian estar ocultos en los datos originales.\n",
    "\n",
    "Estas tablas/dataframes son útiles cuando queremos resumir, reorganizar, identificar patrones o tambien comparar subgrupos de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe creado:\n",
      " StockCode             10002  10080  10120  10123C  10123G  10124A  10124G  \\\n",
      "Country                                                                     \n",
      "Australia               NaN    NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "Austria                 NaN    NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "Bahrain                 NaN    NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "Belgium                 NaN    NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "Brazil                  NaN    NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "Canada                  NaN    NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "Channel Islands         NaN    NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "Cyprus                  NaN    NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "Czech Republic          NaN    NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "Denmark                 NaN    NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "EIRE                   12.0    NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "European Community      NaN    NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "Finland                 NaN    NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "France                372.0    NaN   10.0     NaN     NaN     NaN     NaN   \n",
      "Germany                 1.0    NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "Greece                  NaN    NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "Hong Kong               NaN    NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "Iceland                 NaN    NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "Israel                  NaN    NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "Italy                   NaN    NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "Japan                   1.0    NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "Lebanon                 NaN    NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "Lithuania               NaN    NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "Malta                   NaN    NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "Netherlands             NaN    NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "Norway                  NaN    NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "Poland                  NaN    NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "Portugal                NaN    NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "RSA                     NaN    NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "Saudi Arabia            NaN    NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "Singapore               NaN    NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "Spain                  24.0    NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "Sweden                  NaN    NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "Switzerland            12.0    NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "USA                     NaN    NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "United Arab Emirates    NaN    NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "United Kingdom        615.0  495.0  183.0   -13.0   -38.0    16.0    17.0   \n",
      "Unspecified             NaN    NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "\n",
      "StockCode             10125   10133  10134  ...       M  PADS    POST     S  \\\n",
      "Country                                     ...                               \n",
      "Australia               NaN     NaN    NaN  ...     NaN   NaN     0.0   NaN   \n",
      "Austria                 NaN     NaN    NaN  ...     NaN   NaN    37.0   NaN   \n",
      "Bahrain                 NaN     NaN    NaN  ...     NaN   NaN     NaN   NaN   \n",
      "Belgium                 NaN     NaN    NaN  ...     NaN   NaN   272.0   NaN   \n",
      "Brazil                  NaN     NaN    NaN  ...     NaN   NaN     NaN   NaN   \n",
      "Canada                  NaN    40.0    NaN  ...     NaN   NaN     1.0   NaN   \n",
      "Channel Islands         NaN     NaN    NaN  ...     0.0   NaN     NaN   NaN   \n",
      "Cyprus                  NaN     NaN    NaN  ...     0.0   NaN     1.0   NaN   \n",
      "Czech Republic          NaN     NaN    NaN  ...     NaN   NaN     0.0   NaN   \n",
      "Denmark                 NaN     NaN    NaN  ...     NaN   NaN    41.0   NaN   \n",
      "EIRE                    NaN    40.0    NaN  ...    -2.0   NaN     NaN   NaN   \n",
      "European Community      NaN     NaN    NaN  ...     NaN   NaN     9.0   NaN   \n",
      "Finland                 NaN     NaN    NaN  ...     2.0   NaN    89.0   NaN   \n",
      "France                470.0     NaN    NaN  ...   -16.0   NaN   803.0   NaN   \n",
      "Germany               120.0     NaN    NaN  ...     2.0   NaN  1104.0   NaN   \n",
      "Greece                  NaN     NaN    NaN  ...     NaN   NaN     6.0   NaN   \n",
      "Hong Kong               NaN     NaN    NaN  ...     0.0   NaN     2.0   NaN   \n",
      "Iceland                 NaN     NaN    NaN  ...     NaN   NaN     NaN   NaN   \n",
      "Israel                  NaN    20.0    NaN  ...     NaN   NaN     NaN   NaN   \n",
      "Italy                   NaN     NaN    NaN  ...    -1.0   NaN    44.0   NaN   \n",
      "Japan                   NaN     NaN    NaN  ...    -3.0   NaN     NaN   NaN   \n",
      "Lebanon                 NaN     NaN    NaN  ...     NaN   NaN     NaN   NaN   \n",
      "Lithuania               NaN     NaN    NaN  ...     NaN   NaN     NaN   NaN   \n",
      "Malta                   NaN     NaN    NaN  ...     NaN   NaN    10.0   NaN   \n",
      "Netherlands             NaN     NaN    NaN  ...  -480.0   NaN    99.0   NaN   \n",
      "Norway                  NaN     NaN    NaN  ...     0.0   NaN    57.0   NaN   \n",
      "Poland                  NaN     NaN    NaN  ...     NaN   NaN     9.0   NaN   \n",
      "Portugal                NaN    20.0    NaN  ...     1.0   NaN    97.0   NaN   \n",
      "RSA                     NaN     NaN    NaN  ...     1.0   NaN     NaN   NaN   \n",
      "Saudi Arabia            NaN     NaN    NaN  ...     NaN   NaN     NaN   NaN   \n",
      "Singapore               NaN     NaN    NaN  ...     0.0   NaN     NaN   NaN   \n",
      "Spain                   NaN     NaN    NaN  ...    -3.0   NaN   209.0   NaN   \n",
      "Sweden                  NaN     NaN    NaN  ...     1.0   NaN    37.0   NaN   \n",
      "Switzerland            20.0    10.0    NaN  ...     NaN   NaN    97.0   NaN   \n",
      "USA                     NaN     NaN    NaN  ...     NaN   NaN     NaN   NaN   \n",
      "United Arab Emirates    NaN     NaN    NaN  ...     NaN   NaN     1.0   NaN   \n",
      "United Kingdom        686.0  2645.0  -19.0  ...  3662.0   4.0  3328.0 -59.0   \n",
      "Unspecified             NaN     NaN    NaN  ...     NaN   NaN     NaN   NaN   \n",
      "\n",
      "StockCode             gift_0001_10  gift_0001_20  gift_0001_30  gift_0001_40  \\\n",
      "Country                                                                        \n",
      "Australia                      NaN           NaN           NaN           NaN   \n",
      "Austria                        NaN           NaN           NaN           NaN   \n",
      "Bahrain                        NaN           NaN           NaN           NaN   \n",
      "Belgium                        NaN           NaN           NaN           NaN   \n",
      "Brazil                         NaN           NaN           NaN           NaN   \n",
      "Canada                         NaN           NaN           NaN           NaN   \n",
      "Channel Islands                NaN           NaN           NaN           NaN   \n",
      "Cyprus                         NaN           NaN           NaN           NaN   \n",
      "Czech Republic                 NaN           NaN           NaN           NaN   \n",
      "Denmark                        NaN           NaN           NaN           NaN   \n",
      "EIRE                           NaN           NaN           NaN           NaN   \n",
      "European Community             NaN           NaN           NaN           NaN   \n",
      "Finland                        NaN           NaN           NaN           NaN   \n",
      "France                         NaN           NaN           NaN           NaN   \n",
      "Germany                        NaN           NaN           NaN           NaN   \n",
      "Greece                         NaN           NaN           NaN           NaN   \n",
      "Hong Kong                      NaN           NaN           NaN           NaN   \n",
      "Iceland                        NaN           NaN           NaN           NaN   \n",
      "Israel                         NaN           NaN           NaN           NaN   \n",
      "Italy                          NaN           NaN           NaN           NaN   \n",
      "Japan                          NaN           NaN           NaN           NaN   \n",
      "Lebanon                        NaN           NaN           NaN           NaN   \n",
      "Lithuania                      NaN           NaN           NaN           NaN   \n",
      "Malta                          NaN           NaN           NaN           NaN   \n",
      "Netherlands                    NaN           NaN           NaN           NaN   \n",
      "Norway                         NaN           NaN           NaN           NaN   \n",
      "Poland                         NaN           NaN           NaN           NaN   \n",
      "Portugal                       NaN           NaN           NaN           NaN   \n",
      "RSA                            NaN           NaN           NaN           NaN   \n",
      "Saudi Arabia                   NaN           NaN           NaN           NaN   \n",
      "Singapore                      NaN           NaN           NaN           NaN   \n",
      "Spain                          NaN           NaN           NaN           NaN   \n",
      "Sweden                         NaN           NaN           NaN           NaN   \n",
      "Switzerland                    NaN           NaN           NaN           NaN   \n",
      "USA                            NaN           NaN           NaN           NaN   \n",
      "United Arab Emirates           NaN           NaN           NaN           NaN   \n",
      "United Kingdom                39.0          20.0          37.0           3.0   \n",
      "Unspecified                    NaN           NaN           NaN           NaN   \n",
      "\n",
      "StockCode             gift_0001_50    m  \n",
      "Country                                  \n",
      "Australia                      NaN  NaN  \n",
      "Austria                        NaN  NaN  \n",
      "Bahrain                        NaN  NaN  \n",
      "Belgium                        NaN  NaN  \n",
      "Brazil                         NaN  NaN  \n",
      "Canada                         NaN  NaN  \n",
      "Channel Islands                NaN  NaN  \n",
      "Cyprus                         NaN  NaN  \n",
      "Czech Republic                 NaN  NaN  \n",
      "Denmark                        NaN  NaN  \n",
      "EIRE                           NaN  NaN  \n",
      "European Community             NaN  NaN  \n",
      "Finland                        NaN  NaN  \n",
      "France                         NaN  NaN  \n",
      "Germany                        NaN  NaN  \n",
      "Greece                         NaN  NaN  \n",
      "Hong Kong                      NaN  NaN  \n",
      "Iceland                        NaN  NaN  \n",
      "Israel                         NaN  NaN  \n",
      "Italy                          NaN  NaN  \n",
      "Japan                          NaN  NaN  \n",
      "Lebanon                        NaN  NaN  \n",
      "Lithuania                      NaN  NaN  \n",
      "Malta                          NaN  NaN  \n",
      "Netherlands                    NaN  NaN  \n",
      "Norway                         NaN  NaN  \n",
      "Poland                         NaN  NaN  \n",
      "Portugal                       NaN  NaN  \n",
      "RSA                            NaN  NaN  \n",
      "Saudi Arabia                   NaN  NaN  \n",
      "Singapore                      NaN  NaN  \n",
      "Spain                          NaN  NaN  \n",
      "Sweden                         NaN  NaN  \n",
      "Switzerland                    NaN  NaN  \n",
      "USA                            NaN  NaN  \n",
      "United Arab Emirates           NaN  NaN  \n",
      "United Kingdom                 4.0  1.0  \n",
      "Unspecified                    NaN  NaN  \n",
      "\n",
      "[38 rows x 4070 columns]\n"
     ]
    }
   ],
   "source": [
    "pivot_table = pd.pivot_table(retail_data, values = 'Quantity', index = 'Country', columns = 'StockCode', aggfunc = 'sum')\n",
    "# values, queremos que se value la cantidad, Quantity (información con la que se llena la tabla digamos)\n",
    "# index, cual va a ser nuestro index, los datos únicos que recolectará (eje vertial)\n",
    "# columns, información que recolectará para nuestro eje vertical. ESTE ES EL ÚNICO QUE PUEDE RECIBIR UNA LISTA DE COLUMNAS A UTILIZAR\n",
    "# aggfunc, operación a realizar\n",
    "# NaN no se registraron ventas en ese caso\n",
    "print('Dataframe creado:\\n', pivot_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desapilar y apilar información con stack()\n",
    "Retomemos a un dataframe que habiamos creado y bueno, el uso que le veo es para presentación y visualización de información por el momento, quizá tengo otros pero debemos de tenerlo presente al igual que todas las herramientas para un buen uso de Pandas... lo que hace es cambiar el orden en el que se presentan los datos en el dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame normal:\n",
      "    A  B  C\n",
      "0  a  b  c\n",
      "1  1  3  5\n",
      "2  2  4  6\n",
      "\n",
      "DataFrame desapilado:\n",
      " 0  A    a\n",
      "   B    b\n",
      "   C    c\n",
      "1  A    1\n",
      "   B    3\n",
      "   C    5\n",
      "2  A    2\n",
      "   B    4\n",
      "   C    6\n",
      "dtype: object\n",
      "\n",
      "DataFrame de nuevo apilado con Unstacked:\n",
      "    A  B  C\n",
      "0  a  b  c\n",
      "1  1  3  5\n",
      "2  2  4  6\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'A' : ['a', 1, 2],\n",
    "    'B' : ['b', 3, 4],\n",
    "    'C' : ['c', 5, 6]\n",
    "})\n",
    "print('DataFrame normal:\\n', df)\n",
    "\n",
    "df_stack = df.stack()\n",
    "print('\\nDataFrame desapilado:\\n', df_stack)\n",
    "\n",
    "df_unstacked = df_stack.unstack()\n",
    "print('\\nDataFrame de nuevo apilado con Unstacked:\\n', df_unstacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combinación de datos con múltiples tablas.\n",
    "Pandas nos ofrece algunos métodos para realizar esta fusión de dataframes y son los siguientes.\n",
    "- Merge\n",
    "- Concat\n",
    "- Join \n",
    "La combinación de múltiples tablas permite integrar información de diversas fuentes para tener al final un análisis mas integral.\n",
    "\n",
    "Usaremos para este caso con ejemplo un df mas pequeño.\n",
    "\n",
    "# Merge\n",
    "Para el caso de merge...\n",
    "- UNIÓN INTERNA\n",
    "Recibe como argumentos los df con los que hará la fusión o comparará valores, posterior a ello va EN BASE A QUE quieres realizar el merge, en este caso en base a las key, despues va COMO lo quieres hacer, en este caso con inner, osea con datos que estan ahí adentro.\n",
    "\n",
    "Estas funciones recuerdan un poco a las que tenemos en SQL.\n",
    "\n",
    "Al correrlo nos dará empty, vacio debido a que no tenemos llaves iguales en ambas tablas, si bien podemos crear una añadiendo G en AMBAS con su respectivo valor, este se nos mostrará.\n",
    "\n",
    "- UNIÓN EXTERNA \n",
    "Me devuelve todos los valores base al ejecutarlo (de ambos df), en este caso me da la fusión de las tablas indicando si hay una relación de mis keys con sus valores. Observa el código al ejecutarlo. En este caso muestra que no hay valores relacionados con nuestros datos a excepción con la KEY G que agregamos.\n",
    "\n",
    "- Right merge, simplemente cambia en el parámetro how la palabra right\n",
    "Aquí tomamos en cuenta todas las filas del segundo df y solo las coincidentes con la derecha son las que se mostrarán, mostrará coincidencias con respecto a la tabla derecha, segundo argumento.\n",
    "\n",
    "- Lef merge, simplemente cambia en el parámetro how la palabra left\n",
    "Mostrará coincidencias respecto a la tabla izquierda, primer argumento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner Merge\n",
      "  key  value  value2\n",
      "0   G      7       8\n",
      "\n",
      "Outer Merge\n",
      "  key  value  value2\n",
      "0   A    1.0     NaN\n",
      "1   B    2.0     NaN\n",
      "2   C    3.0     NaN\n",
      "3   D    NaN     4.0\n",
      "4   E    NaN     5.0\n",
      "5   F    NaN     6.0\n",
      "6   G    7.0     8.0\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({\n",
    "    'key' : ['A', 'B', 'C', 'G'],\n",
    "    'value' : [1,2,3,7]\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'key' : ['D', 'E', 'F', 'G'],\n",
    "    'value2' : [4,5,6,8]\n",
    "})\n",
    "\n",
    "print('Inner Merge')\n",
    "inner_merge = pd.merge(df1, df2, on = 'key', how = 'inner')\n",
    "print(inner_merge)\n",
    "\n",
    "print('\\nOuter Merge')\n",
    "outer_merge = pd.merge(df1, df2, on='key', how = 'outer')\n",
    "print(outer_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenación de df\n",
    "Podemos hacerlo de manera vertical y de manera horizontal, toma en cuenta que estmaos usando ejemplos pequeños para ver de manera visual como funciona este concepto.\n",
    "\n",
    "Observarás que la información simplemente se une de una tabla con otra, si hay coincidencias las toma por separado, no las fusiona, simplemente es una tabla unida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 4-5: malformed \\N character escape (1298438877.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[32], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    print('DF3:\\N', df3)\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 4-5: malformed \\N character escape\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.DataFrame({\n",
    "    'A' : ['AO', 'A1', 'A2'],\n",
    "    'B' : ['B0', 'B1', 'B2']\n",
    "})\n",
    "\n",
    "df4 = pd.DataFrame({\n",
    "    'A' : ['A3', 'A4', 'A5'],\n",
    "    'B' : ['B3', 'B4', 'B5']\n",
    "})\n",
    "\n",
    "print('DF3:\\n', df3)\n",
    "print('\\nDF4:\\n', df4)\n",
    "\n",
    "vertical_concat = pd.concat([df3,df4])\n",
    "print('Concatenación vertical:n', vertical_concat)\n",
    "\n",
    "horizontal_concat = pd.concat([df3, df4], axis=1) #Si no le damos el axis esta tomando por defecto el 0, si queremos que sea horizontal tenemos que especificar que el eje es igual 1\n",
    "print('Concatenación Horizontal:\\n', horizontal_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joined, índices más manuales.\n",
    "Como bien mencionabamos, concat simplemente une las tablas, no hay fusión de datos.\n",
    "Joined combina dataframes con base a un índice o columna clave.\n",
    "\n",
    "Lo que hará es tomar los indices y luego las columans las apila una a otra pero con los indices  que tiene coindicencias.\n",
    "\n",
    "La principal diferencia entre merge y join, es que en join estamos usando los índices como vimos, tenemos dos dataframes que comparten información y lo que hace es apilar las coincidencias con los índices que se estan especificando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF5:\n",
      "      A   B\n",
      "K0  A0  B0\n",
      "K1  A1  B1\n",
      "K2  A2  B2\n",
      "\n",
      "DF6:\n",
      "      C   D\n",
      "K0  C0  DO\n",
      "K1  C1  D1\n",
      "K2  C2  D2\n",
      "\n",
      "Con join:\n",
      "      A   B   C   D\n",
      "K0  A0  B0  C0  DO\n",
      "K1  A1  B1  C1  D1\n",
      "K2  A2  B2  C2  D2\n"
     ]
    }
   ],
   "source": [
    "# Ejercicios con join()\n",
    "df5 = pd.DataFrame({\n",
    "    'A': ['A0', 'A1', 'A2'],\n",
    "    'B': ['B0', 'B1', 'B2']\n",
    "}, index = ['K0', 'K1', 'K2']) \n",
    "\n",
    "df6 = pd.DataFrame({\n",
    "    'C': ['C0', 'C1', 'C2'],\n",
    "    'D': ['DO', 'D1', 'D2']\n",
    "}, index = ['K0', 'K1', 'K2'])\n",
    "\n",
    "print('DF5:\\n', df5)\n",
    "print('\\nDF6:\\n', df6)\n",
    "\n",
    "joined = df5.join(df6, how='inner')\n",
    "print('\\nCon join:\\n', joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manejo de Series Temporales en Pandas\n",
    "Para hacer esto es importante revisar que las columnas que las columnas que estan en fechas y en horas esten en su formato adecuado. Pnadas maneja este tipo de columnas con el tipo de dato DATETIME tal que les permite realzar tareas complejas como sampling, filtrado y análisis de tendencias con mayor eficiencia y precisión.\n",
    "\n",
    "# Ritual a seguir para preparar nuestro DataFrame de análisis.\n",
    "Cuando los datos provienen de archivos csv u otras fuentes es común que las fechas vengan en un formato str, para poder realizar una anlisis temporal efectivo es necsario pasarlo al tipo de dato datetime permitiendonos usar más herrameintas además.\n",
    "\n",
    "Recuerda que para revisar esto usamos el método de pandas info()\n",
    "df.info()\n",
    "Para la conversión hacemos lo sigueinte:\n",
    "\n",
    "Recuerda que no estamos creando un nuevo df, estamos convirtiendo nuestro df, en específico una columna.\n",
    "\n",
    "Después vamos a eliminar los valores NO disponibles, le pasamos un sobconjunto de nuestro conjunto que será la información de una columna como primer parámetro.\n",
    "El segundo parámetro inplace significa que queremos hacer una modificación sobre el dataframe que estmaos trabajando Y NO UNA COPIA COMO TAL.\n",
    "\n",
    "Después vamos a establecer como índice la fecha con su respectiva hora, esto lo hacemos de la siguiente manera:\n",
    "df.set_index('InvoiceDate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 541909 entries, 0 to 541908\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count   Dtype         \n",
      "---  ------         --------------   -----         \n",
      " 0   InvoiceNo      541909 non-null  object        \n",
      " 1   StockCode      541909 non-null  object        \n",
      " 2   Description    540455 non-null  object        \n",
      " 3   Quantity       541909 non-null  int64         \n",
      " 4   InvoiceDate    541909 non-null  datetime64[ns]\n",
      " 5   UnitPrice      541909 non-null  float64       \n",
      " 6   customerserID     406829 non-null  float64       \n",
      " 7   Country        541909 non-null  object        \n",
      " 8   TotalPrice     541909 non-null  float64       \n",
      " 9   HighValue      541909 non-null  bool          \n",
      " 10  DiscountPrice  541909 non-null  float64       \n",
      " 11  PriceCategory  541909 non-null  object        \n",
      "dtypes: bool(1), datetime64[ns](1), float64(4), int64(1), object(5)\n",
      "memory usage: 46.0+ MB\n",
      "\n",
      "Eliminamos valores NO disponibles o nulos...\n"
     ]
    }
   ],
   "source": [
    "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate']) #Como vamos a remplazar toda la columna le vamos a pasar el dataframe con el nombre de la columna\n",
    "df.info()\n",
    "\n",
    "print('\\nEliminamos valores NO disponibles o nulos...')\n",
    "df.dropna(subset=['InvoiceDate'], inplace=True) #Le estamos diciendo que de un subconjunto en específico, la información contenida dentro de una columna es un subset.\n",
    "\n",
    "#Establecemos nuestro índice. INPLACE LO PODEMOS ESPECIFICAR TAMBIEN AQUÍ. De hecho nos será útil más adelante.\n",
    "\n",
    "print('\\nEstableciendo índice...')\n",
    "df.set_index('InvoiceDate', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práticas de SQL - Normalización (información atómica)\n",
    "Observa la información que tenemos en InvoiceDate...\n",
    "Año - Mes - Día - Hora - Minutos - Segundos\n",
    "Tambien podemos dividir o fraccionar cada una de estas secciones para crear nuevas columnas, esto recuerda un poco a las normalizaciones que se deben de hacer para el registro de datos en SQL, la información debe ser atómica.\n",
    "\n",
    "Pero debemos de tener cuidado pues al usar inplace recuerda que esta modificación la esta realizando con nuestro dataframe original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREAMOS UNA NUEVA COLUMNA \"Year\"\n",
    "df['Year'] = df.index.year\n",
    "df['Month'] = df.index.month\n",
    "df['Day'] = df.index.day\n",
    "#Día de la semana QUE SE REFIERE A NÚMEROS DEL 1 AL 7\n",
    "df['Weekday'] = df.index.weekday\n",
    "df['Hour'] = df.index.hour\n",
    "\n",
    "print(df['Year'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede que nos de un error que indica que el RangeIndex no tiene el atributo year, ES POR ELLO QUE DEBEMOS DE REALIZAR LA MODIFICACIÓN DENTRO DE LA SECCIÓN DONDE ESTABLECIMOS NUESTRO NUEVO INDICE CON INPLACE.\n",
    "Haciendo eso ya puedo establecer esa nueva columna y empezar a hacerlo con las demás secciones, extrayendo cada uno de esos atributos y ponerlos en una nueva columna.\n",
    "\n",
    "# Imprimir nuestras modificaciones dentro del DataFrame para verificar que todo esta correcto.\n",
    "df\n",
    "Simplemente lo llamo y ejecuto.\n",
    "\n",
    "# Eliminar columnas creadas ante algún error.\n",
    "Si simplemente corrigo la linea de código en donde cree esa columna TENDRÍA DOS COLUMNAS, la del error y la corregida, es por ello que se deben de eliminar si o si ante algún error, recuerda que estamos modificando nuestra información original.\n",
    "\n",
    "Analiza la sintaxis, no es compleja.\n",
    "df = df.drop(columns = ['NameofColumn'])\n",
    "\n",
    "Con ello queda eliminada esa columna.\n",
    "\n",
    "# Añadir columna - Especifica despues de que columan se añadirá\n",
    "Si simplemente agregamos la columan corregida con la sintaxis vista...\n",
    "df['Year'] = df.index.year\n",
    "Este lo añadirá hasta el final si no se especifica claro, hay que tener cuidado en eso dentro de la presentación de nuestro datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOC\n",
    "Cuando en el índice estamos manejando el tipo de dato DateTime tenemos un recurso que podemos usar a nuestro favor y es que cuando utilizamos el metodo LOC podemos acceder directamente al año o mes que queremos extraer como información.\n",
    "\n",
    "Lo estaremos haciendo con base al indice pero tambien podemos extraer información no necesariamente con respecto al índice, si no que a una columna en específico.\n",
    "\n",
    "Entonces tendremos dos maneras de tratar el mismo dataframe.\n",
    "\n",
    "Tambien con LOC podemos extraer po ejemplo un rango de fechas que le especifiquemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2011 = df.loc['2011'] #No le estoy diciendo el nombre de columna, ni que lo agrupe, simplemente que extraiga esa información\n",
    "df_2011.head()\n",
    "\n",
    "#Podemos seguir añadiendo información para extraer.\n",
    "df_2011_dic = df.loc['2011-12'] #Por el formato que estamos manejando\n",
    "df_2011_dic.head()\n",
    "\n",
    "print('\\nExtrayendo un rango de fechas con LOC...\\n')\n",
    "\n",
    "df_date_range = df.loc['2010-12-02' : '2010-12-15']\n",
    "df_date_range.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a crear rangos de fechas en donde vamos a utilizar en información nueva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range_new = pd.date_range(start='2024-01-01', end='2024-12-31', freq='D') #Parametros: inicio, final y LE PODEMOS INDICAR LA FRECUENCIA\n",
    "\n",
    "date_range_new\n",
    "#Obtenemos una Serie de Pandas QUE PODEMOS AGREGAR A UNA COLUMNA NUEVA\n",
    "\n",
    "df_dates = pd.DataFrame(date_range_new, columns=['Date'])\n",
    "#De donde obtendrá la información \n",
    "#En donde establecerá la información, en este caso creará una columna ['Column'] nueva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ya tenemos los datos como queremos para poder realizar nuestros análisis, ya solo queda presentar nuestra información."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
